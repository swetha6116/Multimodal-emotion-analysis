{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d96e43",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:43.461404Z",
          "iopub.status.busy": "2023-11-21T04:45:43.461082Z",
          "iopub.status.idle": "2023-11-21T04:45:56.526814Z",
          "shell.execute_reply": "2023-11-21T04:45:56.525860Z"
        },
        "papermill": {
          "duration": 13.074091,
          "end_time": "2023-11-21T04:45:56.529230",
          "exception": false,
          "start_time": "2023-11-21T04:45:43.455139",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d96e43",
        "outputId": "aa8461a1-a89e-46cb-a6ed-748ef3441de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215ba78e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:56.540475Z",
          "iopub.status.busy": "2023-11-21T04:45:56.539953Z",
          "iopub.status.idle": "2023-11-21T04:45:56.564273Z",
          "shell.execute_reply": "2023-11-21T04:45:56.563427Z"
        },
        "papermill": {
          "duration": 0.031945,
          "end_time": "2023-11-21T04:45:56.566133",
          "exception": false,
          "start_time": "2023-11-21T04:45:56.534188",
          "status": "completed"
        },
        "tags": [],
        "id": "215ba78e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import gamma\n",
        "\n",
        "\n",
        "class CSO:\n",
        "\n",
        "    def __init__(self, fitness, P=5, n=2, pa=0.25, beta=5, bound=None,\n",
        "                plot=False, min=True, verbose=False, Tmax=10):\n",
        "\n",
        "\n",
        "        self.fitness = fitness\n",
        "        self.P = P\n",
        "        self.n = n\n",
        "        self.Tmax = Tmax\n",
        "        self.pa = pa\n",
        "        self.beta = beta\n",
        "        self.bound = bound\n",
        "        self.plot = plot\n",
        "        self.min = min\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # X = (U-L)*rand + L (U AND L ARE UPPER AND LOWER BOUND OF X)\n",
        "        # U AND L VARY BASED ON THE DIFFERENT DIMENSION OF X\n",
        "\n",
        "        self.X = []\n",
        "\n",
        "        if bound is not None:\n",
        "            for (U, L) in bound:\n",
        "                x = (U-L)*np.random.rand(P,) + L\n",
        "                self.X.append(x)\n",
        "            self.X = np.array(self.X).T\n",
        "        else:\n",
        "            self.X = np.random.randn(P,n)\n",
        "\n",
        "    def update_position_1(self):\n",
        "\n",
        "\n",
        "        num = gamma(1+self.beta)*np.sin(np.pi*self.beta/2)\n",
        "        den = gamma((1+self.beta)/2)*self.beta*(2**((self.beta-1)/2))\n",
        "        ﾏブ = (num/den)**(1/self.beta)\n",
        "        ﾏプ = 1\n",
        "        u = np.random.normal(0, ﾏブ, self.n)\n",
        "        v = np.random.normal(0, ﾏプ, self.n)\n",
        "        S = u/(np.abs(v)**(1/self.beta))\n",
        "\n",
        "        # DEFINING GLOBAL BEST SOLUTION BASED ON FITNESS VALUE\n",
        "\n",
        "        for i in range(self.P):\n",
        "            if i==0:\n",
        "                self.best = self.X[i,:].copy()\n",
        "                self.res = self.fitness(self.best)\n",
        "            else:\n",
        "                self.best,self.res = self.optimum(self.best, self.X[i,:])\n",
        "\n",
        "        # Xnew = self.X.copy()\n",
        "        # for i in range(self.P):\n",
        "        #     Xnew[i,:] += np.random.randn(self.n)*0.01*S*(Xnew[i,:]-self.best)\n",
        "        #     self.X[i,:] = self.optimum(Xnew[i,:], self.X[i,:])\n",
        "\n",
        "\n",
        "    def update_position_2(self):\n",
        "\n",
        "\n",
        "        Xnew = self.X.copy()\n",
        "        Xold = self.X.copy()\n",
        "        for i in range(self.P):\n",
        "            d1,d2 = np.random.randint(0,5,2)\n",
        "            for j in range(self.n):\n",
        "                r = np.random.rand()\n",
        "                if r < self.pa:\n",
        "                    Xnew[i,j] += np.random.rand()*(Xold[d1,j]-Xold[d2,j])\n",
        "            self.X[i,:],_ = self.optimum(Xnew[i,:], self.X[i,:])\n",
        "\n",
        "    def optimum(self, best, particle_x):\n",
        "\n",
        "        if self.min:\n",
        "            curr = self.fitness(particle_x)\n",
        "            if self.res > curr:\n",
        "                best = particle_x.copy()\n",
        "                self.res = curr\n",
        "        else:\n",
        "            curr = self.fitness(particle_x)\n",
        "            if self.res < curr:\n",
        "                best = particle_x.copy()\n",
        "                self.res = curr\n",
        "        return best,curr\n",
        "\n",
        "    def clip_X(self):\n",
        "\n",
        "        # IF BOUND IS SPECIFIED THEN CLIP 'X' VALUES SO THAT THEY ARE IN THE SPECIFIED RANGE\n",
        "\n",
        "        if self.bound is not None:\n",
        "            for i in range(self.n):\n",
        "                xmin, xmax = self.bound[i]\n",
        "                self.X[:,i] = np.clip(self.X[:,i], xmin, xmax)\n",
        "\n",
        "    def execute(self):\n",
        "\n",
        "\n",
        "        self.fitness_time, self.time = [], []\n",
        "\n",
        "        self.optimum_res = None\n",
        "        self.optimum_best = None\n",
        "\n",
        "\n",
        "        for t in range(self.Tmax):\n",
        "            self.update_position_1()\n",
        "            self.clip_X()\n",
        "            self.update_position_2()\n",
        "            self.clip_X()\n",
        "            self.fitness_time.append(self.res)\n",
        "            self.time.append(t)\n",
        "            if self.verbose:\n",
        "                print('Iteration:  ',t,'| best local fitness (cost):',round(self.res,7))\n",
        "\n",
        "            if self.optimum_res == None:\n",
        "              self.optimum_res = self.res\n",
        "              self.optimum_best = self.best\n",
        "            elif self.min:\n",
        "              if self.optimum_res > self.res:\n",
        "                self.optium_res = self.res\n",
        "                self.optimum_best = self.best\n",
        "            elif self.min == False:\n",
        "              if self.optimum_res < self.res:\n",
        "                self.optium_res = self.res\n",
        "                self.optimum_best = self.best\n",
        "\n",
        "\n",
        "\n",
        "        print('\\nOPTIMUM SOLUTION\\n  >', np.round(self.optimum_best.reshape(-1),7).tolist())\n",
        "        print('\\nOPTIMUM FITNESS\\n  >', np.round(self.optimum_res,7))\n",
        "        print()\n",
        "        if self.plot:\n",
        "            self.Fplot()\n",
        "\n",
        "    def Fplot(self):\n",
        "\n",
        "        # PLOTS GLOBAL FITNESS (OR COST) VALUE VS ITERATION GRAPH\n",
        "\n",
        "        plt.plot(self.time, self.fitness_time)\n",
        "        plt.title('Fitness value vs Iteration')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Fitness value')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56fb4ea5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:56.576266Z",
          "iopub.status.busy": "2023-11-21T04:45:56.575985Z",
          "iopub.status.idle": "2023-11-21T04:45:58.224201Z",
          "shell.execute_reply": "2023-11-21T04:45:58.223219Z"
        },
        "papermill": {
          "duration": 1.655913,
          "end_time": "2023-11-21T04:45:58.226566",
          "exception": false,
          "start_time": "2023-11-21T04:45:56.570653",
          "status": "completed"
        },
        "tags": [],
        "id": "56fb4ea5"
      },
      "outputs": [],
      "source": [
        "video_features = np.load(\"/content/drive/MyDrive/video_features.npy\",allow_pickle=True)\n",
        "audio_features = np.load(\"/content/drive/MyDrive/audio_features_updated.npy\",allow_pickle=True)\n",
        "labels = np.load(\"/content/drive/MyDrive/labels.npy\",allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28bcc5f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.237146Z",
          "iopub.status.busy": "2023-11-21T04:45:58.236839Z",
          "iopub.status.idle": "2023-11-21T04:45:58.573920Z",
          "shell.execute_reply": "2023-11-21T04:45:58.573051Z"
        },
        "papermill": {
          "duration": 0.344594,
          "end_time": "2023-11-21T04:45:58.575979",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.231385",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "28bcc5f7",
        "outputId": "c3a52568-c641-4a05-f8af-81b5575761ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7898c49fb340>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for i in range(len(video_features)):\n",
        "  for k in range(6):\n",
        "    video_features[i][k] = cv2.cvtColor(video_features[i][k], cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(video_features[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8910f8b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.587572Z",
          "iopub.status.busy": "2023-11-21T04:45:58.587299Z",
          "iopub.status.idle": "2023-11-21T04:45:58.591912Z",
          "shell.execute_reply": "2023-11-21T04:45:58.591065Z"
        },
        "papermill": {
          "duration": 0.012684,
          "end_time": "2023-11-21T04:45:58.593889",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.581205",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8910f8b6",
        "outputId": "dcbafc86-2410-448c-b3f0-2094442a9d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1440, 181)\n",
            "(1440, 6, 64, 64, 3)\n",
            "(1440, 8)\n"
          ]
        }
      ],
      "source": [
        "print(audio_features.shape)\n",
        "print(video_features.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c96b4de6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.605336Z",
          "iopub.status.busy": "2023-11-21T04:45:58.605039Z",
          "iopub.status.idle": "2023-11-21T04:45:58.652422Z",
          "shell.execute_reply": "2023-11-21T04:45:58.651614Z"
        },
        "papermill": {
          "duration": 0.055779,
          "end_time": "2023-11-21T04:45:58.654848",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.599069",
          "status": "completed"
        },
        "tags": [],
        "id": "c96b4de6"
      },
      "outputs": [],
      "source": [
        "video_features_train,video_features_test,audio_features_train,audio_features_test,labels_train,labels_test = train_test_split(video_features,audio_features,labels,test_size=0.2,random_state=101)\n",
        "video_features_test,video_features_val,audio_features_test,audio_features_val,labels_test,labels_val = train_test_split(video_features_test,audio_features_test,labels_test,test_size=0.5,random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29e58e9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.666669Z",
          "iopub.status.busy": "2023-11-21T04:45:58.666377Z",
          "iopub.status.idle": "2023-11-21T04:45:58.671761Z",
          "shell.execute_reply": "2023-11-21T04:45:58.670979Z"
        },
        "papermill": {
          "duration": 0.013836,
          "end_time": "2023-11-21T04:45:58.674169",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.660333",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e29e58e9",
        "outputId": "793a136f-6511-4b3e-aaf1-40b54fa13d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1152, 6, 64, 64, 3)\n",
            "(144, 6, 64, 64, 3)\n",
            "(144, 6, 64, 64, 3)\n",
            "(1152, 181)\n",
            "(144, 181)\n",
            "(144, 181)\n",
            "(1152, 8)\n",
            "(144, 8)\n",
            "(144, 8)\n"
          ]
        }
      ],
      "source": [
        "print(video_features_train.shape)\n",
        "print(video_features_val.shape)\n",
        "print(video_features_test.shape)\n",
        "print(audio_features_train.shape)\n",
        "print(audio_features_val.shape)\n",
        "print(audio_features_test.shape)\n",
        "print(labels_train.shape)\n",
        "print(labels_val.shape)\n",
        "print(labels_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a1d3d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.685623Z",
          "iopub.status.busy": "2023-11-21T04:45:58.685360Z",
          "iopub.status.idle": "2023-11-21T04:45:58.712350Z",
          "shell.execute_reply": "2023-11-21T04:45:58.711644Z"
        },
        "papermill": {
          "duration": 0.034853,
          "end_time": "2023-11-21T04:45:58.714297",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.679444",
          "status": "completed"
        },
        "tags": [],
        "id": "c7a1d3d5"
      },
      "outputs": [],
      "source": [
        "# Define the input layers for video and audio\n",
        "input_video = Input(shape=(6, 64, 64, 3))\n",
        "input_audio = Input(shape=(181, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e3c0cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.726143Z",
          "iopub.status.busy": "2023-11-21T04:45:58.725692Z",
          "iopub.status.idle": "2023-11-21T04:45:58.736488Z",
          "shell.execute_reply": "2023-11-21T04:45:58.735671Z"
        },
        "papermill": {
          "duration": 0.018917,
          "end_time": "2023-11-21T04:45:58.738481",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.719564",
          "status": "completed"
        },
        "tags": [],
        "id": "c5e3c0cb"
      },
      "outputs": [],
      "source": [
        "#Define layer Structure of the model\n",
        "def layer_structure():\n",
        "    # Define the video processing layers\n",
        "    conv = ConvLSTM2D(64, 3, activation='gelu', padding='same')(input_video)\n",
        "    conv = Convolution2D(64, 3, activation='gelu', padding='same')(conv)\n",
        "    pool = MaxPooling2D((2, 2), strides=(2, 2))(conv)\n",
        "    conv = Convolution2D(128, 3, activation='gelu', padding='same')(pool)\n",
        "    pool = MaxPooling2D((2, 2), strides=(2, 2))(conv)\n",
        "    conv = Convolution2D(128, 3, activation='gelu', padding='same')(pool)\n",
        "    pool = MaxPooling2D((2, 2), strides=(2, 2))(conv)\n",
        "    conv = Convolution2D(256, 3, activation='gelu', padding='same')(pool)\n",
        "    conv = Convolution2D(256, 3, activation='gelu', padding='same')(pool)\n",
        "    conv = Convolution2D(256, 3, activation='gelu', padding='same')(pool)\n",
        "    pool = MaxPooling2D((2, 2), strides=(2, 2))(conv)\n",
        "    conv = Convolution2D(512, 3, activation='gelu', padding='same')(pool)\n",
        "    conv = Convolution2D(512, 3, activation='gelu', padding='same')(pool)\n",
        "    conv = Convolution2D(512, 3, activation='gelu', padding='same')(pool)\n",
        "    pool = MaxPooling2D((2, 2), strides=(2, 2))(conv)\n",
        "    output_video = Flatten()(pool)\n",
        "\n",
        "    # Define the audio processing layers with dropout and batch normalization\n",
        "    conv = Convolution1D(64, 10, activation='gelu')(input_audio)\n",
        "    conv = Convolution1D(128, 10, activation='gelu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(conv)\n",
        "    pool = MaxPooling1D(8)(conv)\n",
        "    drop = Dropout(0.4)(pool)\n",
        "    bn = BatchNormalization()(drop)\n",
        "    output_audio = Flatten()(bn)\n",
        "\n",
        "    # Concatenate of video and audio features\n",
        "    concatenate = keras.layers.Concatenate()([output_video, output_audio])\n",
        "\n",
        "    # Final fully connected layers\n",
        "    final_layer = Dense(128, activation='gelu')(concatenate)\n",
        "    prediction_layer = Dense(8, activation='softmax')(final_layer)\n",
        "    model = Model(inputs=[input_video, input_audio], outputs=[prediction_layer])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "468f9b00",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.749897Z",
          "iopub.status.busy": "2023-11-21T04:45:58.749648Z",
          "iopub.status.idle": "2023-11-21T04:45:58.754609Z",
          "shell.execute_reply": "2023-11-21T04:45:58.753770Z"
        },
        "papermill": {
          "duration": 0.012763,
          "end_time": "2023-11-21T04:45:58.756480",
          "exception": false,
          "start_time": "2023-11-21T04:45:58.743717",
          "status": "completed"
        },
        "tags": [],
        "id": "468f9b00"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "def optimize(model, LEARNING_RATE):\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    # Compile the model\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model, early_stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2af800",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-21T04:45:58.768240Z",
          "iopub.status.busy": "2023-11-21T04:45:58.767719Z",
          "iopub.status.idle": "2023-11-21T04:45:59.484604Z",
          "shell.execute_reply": "2023-11-21T04:45:59.483323Z"
        },
        "papermill": {
          "duration": 0.72467,
          "end_time": "2023-11-21T04:45:59.486321",
          "exception": true,
          "start_time": "2023-11-21T04:45:58.761651",
          "status": "failed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb2af800",
        "outputId": "4429310a-2baf-4e06-fccf-60c565c8f80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCHS:  96\n",
            "BATCH_SIZE:  42\n",
            "LEARNING_RATE:  0.003911635292154655\n",
            "Epoch 1/96\n",
            "28/28 [==============================] - 36s 594ms/step - loss: 57.2235 - accuracy: 0.1884 - val_loss: 2.6433 - val_accuracy: 0.2361\n",
            "Epoch 2/96\n",
            "28/28 [==============================] - 15s 530ms/step - loss: 2.4955 - accuracy: 0.2830 - val_loss: 2.5207 - val_accuracy: 0.2569\n",
            "Epoch 3/96\n",
            "28/28 [==============================] - 15s 530ms/step - loss: 2.0950 - accuracy: 0.3229 - val_loss: 2.3113 - val_accuracy: 0.2222\n",
            "Epoch 4/96\n",
            "28/28 [==============================] - 15s 534ms/step - loss: 1.9746 - accuracy: 0.3854 - val_loss: 1.9410 - val_accuracy: 0.3333\n",
            "Epoch 5/96\n",
            "28/28 [==============================] - 15s 531ms/step - loss: 1.8166 - accuracy: 0.4184 - val_loss: 1.9675 - val_accuracy: 0.3750\n",
            "Epoch 6/96\n",
            "28/28 [==============================] - 15s 533ms/step - loss: 1.8471 - accuracy: 0.4280 - val_loss: 2.1372 - val_accuracy: 0.3403\n",
            "Epoch 7/96\n",
            "28/28 [==============================] - 15s 533ms/step - loss: 1.7890 - accuracy: 0.4106 - val_loss: 1.9047 - val_accuracy: 0.3611\n",
            "Epoch 8/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.7108 - accuracy: 0.4523 - val_loss: 1.9417 - val_accuracy: 0.3889\n",
            "Epoch 9/96\n",
            "28/28 [==============================] - 15s 544ms/step - loss: 1.7393 - accuracy: 0.4497 - val_loss: 1.9434 - val_accuracy: 0.4028\n",
            "Epoch 10/96\n",
            "28/28 [==============================] - 15s 541ms/step - loss: 1.6347 - accuracy: 0.4835 - val_loss: 1.8905 - val_accuracy: 0.3333\n",
            "Epoch 11/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6271 - accuracy: 0.4861 - val_loss: 1.6553 - val_accuracy: 0.5278\n",
            "Epoch 12/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.6369 - accuracy: 0.4939 - val_loss: 2.4296 - val_accuracy: 0.2014\n",
            "Epoch 13/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6437 - accuracy: 0.5009 - val_loss: 1.8647 - val_accuracy: 0.3542\n",
            "Epoch 14/96\n",
            "28/28 [==============================] - 15s 533ms/step - loss: 1.6630 - accuracy: 0.5043 - val_loss: 1.9035 - val_accuracy: 0.3681\n",
            "Epoch 15/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.5796 - accuracy: 0.5208 - val_loss: 1.9231 - val_accuracy: 0.3750\n",
            "Epoch 16/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.5932 - accuracy: 0.5486 - val_loss: 1.8538 - val_accuracy: 0.4236\n",
            "Epoch 17/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6592 - accuracy: 0.5052 - val_loss: 1.8811 - val_accuracy: 0.5000\n",
            "Epoch 18/96\n",
            "28/28 [==============================] - 15s 534ms/step - loss: 1.5691 - accuracy: 0.5582 - val_loss: 1.7122 - val_accuracy: 0.5556\n",
            "Epoch 19/96\n",
            "28/28 [==============================] - 15s 540ms/step - loss: 1.5362 - accuracy: 0.5564 - val_loss: 1.7389 - val_accuracy: 0.4722\n",
            "Epoch 20/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6271 - accuracy: 0.5295 - val_loss: 1.8400 - val_accuracy: 0.5417\n",
            "Epoch 21/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6036 - accuracy: 0.5573 - val_loss: 2.1563 - val_accuracy: 0.4028\n",
            "Epoch 22/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.4899 - accuracy: 0.5703 - val_loss: 1.6936 - val_accuracy: 0.5139\n",
            "Epoch 23/96\n",
            "28/28 [==============================] - 15s 534ms/step - loss: 1.5245 - accuracy: 0.5625 - val_loss: 2.1590 - val_accuracy: 0.3194\n",
            "Epoch 24/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.6003 - accuracy: 0.5599 - val_loss: 1.9982 - val_accuracy: 0.3889\n",
            "Epoch 25/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.4584 - accuracy: 0.6024 - val_loss: 1.7026 - val_accuracy: 0.5208\n",
            "Epoch 26/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 1.4895 - accuracy: 0.5990 - val_loss: 1.7201 - val_accuracy: 0.4375\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.7553 - accuracy: 0.4653\n",
            "Test loss of the model is -  1.7552648782730103\n",
            "Test accuracy of the model is -  46.52777910232544 %\n",
            "EPOCHS:  90\n",
            "BATCH_SIZE:  36\n",
            "LEARNING_RATE:  0.004183665066564939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n",
            "32/32 [==============================] - 23s 481ms/step - loss: 135.8426 - accuracy: 0.1866 - val_loss: 3.1599 - val_accuracy: 0.2222\n",
            "Epoch 2/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 2.4187 - accuracy: 0.3021 - val_loss: 2.1990 - val_accuracy: 0.3403\n",
            "Epoch 3/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 2.4728 - accuracy: 0.2977 - val_loss: 2.2396 - val_accuracy: 0.3403\n",
            "Epoch 4/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.9962 - accuracy: 0.3446 - val_loss: 1.9937 - val_accuracy: 0.3542\n",
            "Epoch 5/90\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.8884 - accuracy: 0.3741 - val_loss: 2.1154 - val_accuracy: 0.2431\n",
            "Epoch 6/90\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.8795 - accuracy: 0.3715 - val_loss: 2.1794 - val_accuracy: 0.3333\n",
            "Epoch 7/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.7978 - accuracy: 0.4097 - val_loss: 2.0149 - val_accuracy: 0.3750\n",
            "Epoch 8/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.7940 - accuracy: 0.4262 - val_loss: 2.1257 - val_accuracy: 0.2361\n",
            "Epoch 9/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.7641 - accuracy: 0.4123 - val_loss: 2.0199 - val_accuracy: 0.2292\n",
            "Epoch 10/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.7510 - accuracy: 0.4245 - val_loss: 1.9244 - val_accuracy: 0.3056\n",
            "Epoch 11/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.6899 - accuracy: 0.4531 - val_loss: 1.9580 - val_accuracy: 0.3194\n",
            "Epoch 12/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.6751 - accuracy: 0.4783 - val_loss: 1.8406 - val_accuracy: 0.4167\n",
            "Epoch 13/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6967 - accuracy: 0.4609 - val_loss: 1.8880 - val_accuracy: 0.3611\n",
            "Epoch 14/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6681 - accuracy: 0.4965 - val_loss: 1.8374 - val_accuracy: 0.4792\n",
            "Epoch 15/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6265 - accuracy: 0.4835 - val_loss: 1.7345 - val_accuracy: 0.4236\n",
            "Epoch 16/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5969 - accuracy: 0.5104 - val_loss: 1.7432 - val_accuracy: 0.4514\n",
            "Epoch 17/90\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.6295 - accuracy: 0.4861 - val_loss: 1.8730 - val_accuracy: 0.4097\n",
            "Epoch 18/90\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.5605 - accuracy: 0.5373 - val_loss: 2.0830 - val_accuracy: 0.2569\n",
            "Epoch 19/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5900 - accuracy: 0.5095 - val_loss: 1.7524 - val_accuracy: 0.4514\n",
            "Epoch 20/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6494 - accuracy: 0.4861 - val_loss: 2.0513 - val_accuracy: 0.3542\n",
            "Epoch 21/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.6699 - accuracy: 0.5009 - val_loss: 1.7999 - val_accuracy: 0.4514\n",
            "Epoch 22/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6001 - accuracy: 0.5260 - val_loss: 1.7692 - val_accuracy: 0.5069\n",
            "Epoch 23/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.5223 - accuracy: 0.5408 - val_loss: 1.7521 - val_accuracy: 0.4306\n",
            "Epoch 24/90\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.5008 - accuracy: 0.5582 - val_loss: 1.6194 - val_accuracy: 0.5069\n",
            "Epoch 25/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5454 - accuracy: 0.5295 - val_loss: 1.7628 - val_accuracy: 0.4028\n",
            "Epoch 26/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5695 - accuracy: 0.5330 - val_loss: 2.0104 - val_accuracy: 0.3194\n",
            "Epoch 27/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.6013 - accuracy: 0.5208 - val_loss: 1.7978 - val_accuracy: 0.4583\n",
            "Epoch 28/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5553 - accuracy: 0.5503 - val_loss: 1.7857 - val_accuracy: 0.4167\n",
            "Epoch 29/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5170 - accuracy: 0.5686 - val_loss: 1.7721 - val_accuracy: 0.5139\n",
            "Epoch 30/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.5746 - accuracy: 0.5408 - val_loss: 1.9009 - val_accuracy: 0.5000\n",
            "Epoch 31/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.4937 - accuracy: 0.5755 - val_loss: 1.6359 - val_accuracy: 0.5486\n",
            "Epoch 32/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.4480 - accuracy: 0.5877 - val_loss: 1.6547 - val_accuracy: 0.4931\n",
            "Epoch 33/90\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.3981 - accuracy: 0.5998 - val_loss: 1.7200 - val_accuracy: 0.4653\n",
            "Epoch 34/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.4258 - accuracy: 0.5833 - val_loss: 1.6745 - val_accuracy: 0.5278\n",
            "Epoch 35/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.4919 - accuracy: 0.5868 - val_loss: 1.6953 - val_accuracy: 0.4931\n",
            "Epoch 36/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.4750 - accuracy: 0.5929 - val_loss: 1.8312 - val_accuracy: 0.4722\n",
            "Epoch 37/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.4040 - accuracy: 0.5955 - val_loss: 1.7764 - val_accuracy: 0.4653\n",
            "Epoch 38/90\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.4353 - accuracy: 0.6128 - val_loss: 2.2247 - val_accuracy: 0.2778\n",
            "Epoch 39/90\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.4477 - accuracy: 0.6016 - val_loss: 2.4229 - val_accuracy: 0.3819\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 1.7551 - accuracy: 0.4236\n",
            "Test loss of the model is -  1.7551217079162598\n",
            "Test accuracy of the model is -  42.36111044883728 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  51\n",
            "LEARNING_RATE:  0.0016647160917598715\n",
            "Epoch 1/85\n",
            "23/23 [==============================] - 24s 722ms/step - loss: 7.9850 - accuracy: 0.2092 - val_loss: 2.9725 - val_accuracy: 0.1250\n",
            "Epoch 2/85\n",
            "23/23 [==============================] - 15s 650ms/step - loss: 2.3564 - accuracy: 0.3003 - val_loss: 2.5461 - val_accuracy: 0.2292\n",
            "Epoch 3/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 2.0665 - accuracy: 0.3811 - val_loss: 2.5453 - val_accuracy: 0.2569\n",
            "Epoch 4/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 1.8962 - accuracy: 0.4201 - val_loss: 2.1295 - val_accuracy: 0.1875\n",
            "Epoch 5/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 1.7390 - accuracy: 0.4436 - val_loss: 2.0060 - val_accuracy: 0.2778\n",
            "Epoch 6/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 1.6010 - accuracy: 0.5104 - val_loss: 1.9775 - val_accuracy: 0.3194\n",
            "Epoch 7/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 1.5556 - accuracy: 0.5043 - val_loss: 1.8709 - val_accuracy: 0.4306\n",
            "Epoch 8/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 1.4777 - accuracy: 0.5460 - val_loss: 1.8725 - val_accuracy: 0.3611\n",
            "Epoch 9/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.4445 - accuracy: 0.5469 - val_loss: 1.7523 - val_accuracy: 0.4306\n",
            "Epoch 10/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 1.4195 - accuracy: 0.5538 - val_loss: 1.7244 - val_accuracy: 0.4583\n",
            "Epoch 11/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.3108 - accuracy: 0.6137 - val_loss: 1.6876 - val_accuracy: 0.5069\n",
            "Epoch 12/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 1.2604 - accuracy: 0.6337 - val_loss: 1.6858 - val_accuracy: 0.4931\n",
            "Epoch 13/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.1784 - accuracy: 0.6380 - val_loss: 1.5763 - val_accuracy: 0.5486\n",
            "Epoch 14/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.1393 - accuracy: 0.6658 - val_loss: 1.5897 - val_accuracy: 0.5764\n",
            "Epoch 15/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.1160 - accuracy: 0.6884 - val_loss: 1.4682 - val_accuracy: 0.6042\n",
            "Epoch 16/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.0831 - accuracy: 0.7014 - val_loss: 1.4988 - val_accuracy: 0.5625\n",
            "Epoch 17/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 1.0405 - accuracy: 0.7196 - val_loss: 1.7324 - val_accuracy: 0.4444\n",
            "Epoch 18/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.0710 - accuracy: 0.6901 - val_loss: 1.5269 - val_accuracy: 0.5625\n",
            "Epoch 19/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.0766 - accuracy: 0.7066 - val_loss: 1.3193 - val_accuracy: 0.6319\n",
            "Epoch 20/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.0025 - accuracy: 0.7205 - val_loss: 1.3466 - val_accuracy: 0.6181\n",
            "Epoch 21/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.9639 - accuracy: 0.7274 - val_loss: 1.3791 - val_accuracy: 0.5972\n",
            "Epoch 22/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8652 - accuracy: 0.7700 - val_loss: 1.3027 - val_accuracy: 0.6458\n",
            "Epoch 23/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8572 - accuracy: 0.7786 - val_loss: 1.3030 - val_accuracy: 0.6458\n",
            "Epoch 24/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8810 - accuracy: 0.7734 - val_loss: 1.4317 - val_accuracy: 0.5972\n",
            "Epoch 25/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.9576 - accuracy: 0.7405 - val_loss: 1.4139 - val_accuracy: 0.5833\n",
            "Epoch 26/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.9343 - accuracy: 0.7674 - val_loss: 1.3892 - val_accuracy: 0.6528\n",
            "Epoch 27/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8746 - accuracy: 0.7899 - val_loss: 1.2495 - val_accuracy: 0.6528\n",
            "Epoch 28/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.8535 - accuracy: 0.7917 - val_loss: 1.4657 - val_accuracy: 0.6250\n",
            "Epoch 29/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7686 - accuracy: 0.8273 - val_loss: 1.2683 - val_accuracy: 0.6458\n",
            "Epoch 30/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.7366 - accuracy: 0.8472 - val_loss: 1.3757 - val_accuracy: 0.6389\n",
            "Epoch 31/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.7130 - accuracy: 0.8411 - val_loss: 1.4379 - val_accuracy: 0.6458\n",
            "Epoch 32/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.6634 - accuracy: 0.8637 - val_loss: 3.2816 - val_accuracy: 0.3194\n",
            "Epoch 33/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.7196 - accuracy: 0.8464 - val_loss: 1.3991 - val_accuracy: 0.6042\n",
            "Epoch 34/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5949 - accuracy: 0.8828 - val_loss: 1.5398 - val_accuracy: 0.5972\n",
            "Epoch 35/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5754 - accuracy: 0.8924 - val_loss: 1.5698 - val_accuracy: 0.5903\n",
            "Epoch 36/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5475 - accuracy: 0.8915 - val_loss: 1.4744 - val_accuracy: 0.6042\n",
            "Epoch 37/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5315 - accuracy: 0.9062 - val_loss: 2.0260 - val_accuracy: 0.4861\n",
            "Epoch 38/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.4870 - accuracy: 0.9201 - val_loss: 1.7055 - val_accuracy: 0.5625\n",
            "Epoch 39/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5532 - accuracy: 0.8958 - val_loss: 1.6874 - val_accuracy: 0.5764\n",
            "Epoch 40/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.4740 - accuracy: 0.9097 - val_loss: 1.7919 - val_accuracy: 0.5556\n",
            "Epoch 41/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.4673 - accuracy: 0.9201 - val_loss: 1.4838 - val_accuracy: 0.6458\n",
            "Epoch 42/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.4096 - accuracy: 0.9366 - val_loss: 1.7218 - val_accuracy: 0.6042\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.4931 - accuracy: 0.5833\n",
            "Test loss of the model is -  1.4931024312973022\n",
            "Test accuracy of the model is -  58.33333134651184 %\n",
            "EPOCHS:  80\n",
            "BATCH_SIZE:  39\n",
            "LEARNING_RATE:  0.0018805124864760539\n",
            "Epoch 1/80\n",
            "30/30 [==============================] - 25s 571ms/step - loss: 3.8524 - accuracy: 0.2092 - val_loss: 2.6948 - val_accuracy: 0.1250\n",
            "Epoch 2/80\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 2.2751 - accuracy: 0.3012 - val_loss: 2.0557 - val_accuracy: 0.3750\n",
            "Epoch 3/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.9598 - accuracy: 0.3880 - val_loss: 2.0384 - val_accuracy: 0.3611\n",
            "Epoch 4/80\n",
            "30/30 [==============================] - 14s 483ms/step - loss: 1.8640 - accuracy: 0.4019 - val_loss: 1.8728 - val_accuracy: 0.5000\n",
            "Epoch 5/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 1.6799 - accuracy: 0.4575 - val_loss: 1.9345 - val_accuracy: 0.3958\n",
            "Epoch 6/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 1.6863 - accuracy: 0.4740 - val_loss: 1.7559 - val_accuracy: 0.5139\n",
            "Epoch 7/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.4931 - accuracy: 0.5382 - val_loss: 1.6768 - val_accuracy: 0.5556\n",
            "Epoch 8/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.3724 - accuracy: 0.5660 - val_loss: 1.7248 - val_accuracy: 0.4444\n",
            "Epoch 9/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.3493 - accuracy: 0.5946 - val_loss: 1.6386 - val_accuracy: 0.5139\n",
            "Epoch 10/80\n",
            "30/30 [==============================] - 14s 481ms/step - loss: 1.3802 - accuracy: 0.5990 - val_loss: 1.5666 - val_accuracy: 0.5556\n",
            "Epoch 11/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 1.2959 - accuracy: 0.6076 - val_loss: 1.4902 - val_accuracy: 0.5833\n",
            "Epoch 12/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.2426 - accuracy: 0.6363 - val_loss: 1.7230 - val_accuracy: 0.4931\n",
            "Epoch 13/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 1.2699 - accuracy: 0.6389 - val_loss: 1.4766 - val_accuracy: 0.5486\n",
            "Epoch 14/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.2064 - accuracy: 0.6606 - val_loss: 1.6673 - val_accuracy: 0.4444\n",
            "Epoch 15/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.1168 - accuracy: 0.6866 - val_loss: 1.4453 - val_accuracy: 0.5694\n",
            "Epoch 16/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 1.0682 - accuracy: 0.7023 - val_loss: 1.6181 - val_accuracy: 0.5000\n",
            "Epoch 17/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 1.0931 - accuracy: 0.6953 - val_loss: 1.5195 - val_accuracy: 0.5556\n",
            "Epoch 18/80\n",
            "30/30 [==============================] - 14s 481ms/step - loss: 1.0696 - accuracy: 0.7023 - val_loss: 1.7434 - val_accuracy: 0.4792\n",
            "Epoch 19/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.0650 - accuracy: 0.7127 - val_loss: 1.4579 - val_accuracy: 0.6458\n",
            "Epoch 20/80\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.0289 - accuracy: 0.7240 - val_loss: 1.4202 - val_accuracy: 0.6250\n",
            "Epoch 21/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.9873 - accuracy: 0.7509 - val_loss: 1.4673 - val_accuracy: 0.5972\n",
            "Epoch 22/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.9473 - accuracy: 0.7630 - val_loss: 1.6867 - val_accuracy: 0.5000\n",
            "Epoch 23/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.0624 - accuracy: 0.7292 - val_loss: 1.3686 - val_accuracy: 0.6458\n",
            "Epoch 24/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 1.0246 - accuracy: 0.7431 - val_loss: 1.2817 - val_accuracy: 0.6806\n",
            "Epoch 25/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.9547 - accuracy: 0.7674 - val_loss: 1.4892 - val_accuracy: 0.5903\n",
            "Epoch 26/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 0.9440 - accuracy: 0.7665 - val_loss: 1.6871 - val_accuracy: 0.5208\n",
            "Epoch 27/80\n",
            "30/30 [==============================] - 14s 481ms/step - loss: 0.9700 - accuracy: 0.7648 - val_loss: 1.5371 - val_accuracy: 0.6111\n",
            "Epoch 28/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.8366 - accuracy: 0.8073 - val_loss: 1.4854 - val_accuracy: 0.6042\n",
            "Epoch 29/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.7717 - accuracy: 0.8411 - val_loss: 1.3109 - val_accuracy: 0.6389\n",
            "Epoch 30/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.8453 - accuracy: 0.7986 - val_loss: 1.3331 - val_accuracy: 0.6667\n",
            "Epoch 31/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 0.8098 - accuracy: 0.8203 - val_loss: 1.7740 - val_accuracy: 0.5833\n",
            "Epoch 32/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.8358 - accuracy: 0.8194 - val_loss: 1.2433 - val_accuracy: 0.7083\n",
            "Epoch 33/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.8255 - accuracy: 0.8090 - val_loss: 1.4769 - val_accuracy: 0.6111\n",
            "Epoch 34/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.7788 - accuracy: 0.8238 - val_loss: 1.3607 - val_accuracy: 0.6736\n",
            "Epoch 35/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 0.7629 - accuracy: 0.8307 - val_loss: 1.3265 - val_accuracy: 0.6389\n",
            "Epoch 36/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 0.8324 - accuracy: 0.8064 - val_loss: 1.4817 - val_accuracy: 0.6111\n",
            "Epoch 37/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.8102 - accuracy: 0.8212 - val_loss: 1.2569 - val_accuracy: 0.6944\n",
            "Epoch 38/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.7831 - accuracy: 0.8351 - val_loss: 1.4773 - val_accuracy: 0.6111\n",
            "Epoch 39/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.7293 - accuracy: 0.8438 - val_loss: 1.4753 - val_accuracy: 0.6389\n",
            "Epoch 40/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.6888 - accuracy: 0.8663 - val_loss: 1.5126 - val_accuracy: 0.5625\n",
            "Epoch 41/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.6873 - accuracy: 0.8602 - val_loss: 1.5286 - val_accuracy: 0.6736\n",
            "Epoch 42/80\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.6991 - accuracy: 0.8707 - val_loss: 1.2706 - val_accuracy: 0.6806\n",
            "Epoch 43/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 0.7530 - accuracy: 0.8385 - val_loss: 1.3669 - val_accuracy: 0.6458\n",
            "Epoch 44/80\n",
            "30/30 [==============================] - 14s 481ms/step - loss: 0.6716 - accuracy: 0.8559 - val_loss: 1.4537 - val_accuracy: 0.6806\n",
            "Epoch 45/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 0.6537 - accuracy: 0.8594 - val_loss: 1.7019 - val_accuracy: 0.5556\n",
            "Epoch 46/80\n",
            "30/30 [==============================] - 15s 484ms/step - loss: 0.6886 - accuracy: 0.8559 - val_loss: 1.5176 - val_accuracy: 0.5139\n",
            "Epoch 47/80\n",
            "30/30 [==============================] - 14s 482ms/step - loss: 0.6600 - accuracy: 0.8542 - val_loss: 1.4569 - val_accuracy: 0.6042\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 1.3620 - accuracy: 0.6736\n",
            "Test loss of the model is -  1.361991047859192\n",
            "Test accuracy of the model is -  67.36111044883728 %\n",
            "EPOCHS:  98\n",
            "BATCH_SIZE:  62\n",
            "LEARNING_RATE:  0.0032872209120587683\n",
            "Epoch 1/98\n",
            "19/19 [==============================] - 25s 868ms/step - loss: 59.3996 - accuracy: 0.1806 - val_loss: 3.0968 - val_accuracy: 0.1875\n",
            "Epoch 2/98\n",
            "19/19 [==============================] - 16s 848ms/step - loss: 2.4623 - accuracy: 0.2648 - val_loss: 2.2794 - val_accuracy: 0.3333\n",
            "Epoch 3/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 2.1549 - accuracy: 0.3177 - val_loss: 2.1016 - val_accuracy: 0.3194\n",
            "Epoch 4/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.9488 - accuracy: 0.3559 - val_loss: 2.0420 - val_accuracy: 0.3819\n",
            "Epoch 5/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.8398 - accuracy: 0.3819 - val_loss: 1.9128 - val_accuracy: 0.4097\n",
            "Epoch 6/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.8099 - accuracy: 0.3915 - val_loss: 1.9405 - val_accuracy: 0.3403\n",
            "Epoch 7/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.7184 - accuracy: 0.4384 - val_loss: 2.0014 - val_accuracy: 0.2847\n",
            "Epoch 8/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.7124 - accuracy: 0.4540 - val_loss: 1.9809 - val_accuracy: 0.3889\n",
            "Epoch 9/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.6871 - accuracy: 0.4609 - val_loss: 2.1627 - val_accuracy: 0.3056\n",
            "Epoch 10/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.6472 - accuracy: 0.4601 - val_loss: 2.5604 - val_accuracy: 0.2569\n",
            "Epoch 11/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.6296 - accuracy: 0.4887 - val_loss: 2.3551 - val_accuracy: 0.2708\n",
            "Epoch 12/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.5663 - accuracy: 0.5165 - val_loss: 1.9669 - val_accuracy: 0.3958\n",
            "Epoch 13/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.5486 - accuracy: 0.5174 - val_loss: 1.7582 - val_accuracy: 0.4653\n",
            "Epoch 14/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.5091 - accuracy: 0.5304 - val_loss: 1.9055 - val_accuracy: 0.4375\n",
            "Epoch 15/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4406 - accuracy: 0.5651 - val_loss: 1.7864 - val_accuracy: 0.4653\n",
            "Epoch 16/98\n",
            "19/19 [==============================] - 15s 810ms/step - loss: 1.3739 - accuracy: 0.5981 - val_loss: 1.9532 - val_accuracy: 0.3056\n",
            "Epoch 17/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.4013 - accuracy: 0.6016 - val_loss: 1.6896 - val_accuracy: 0.5486\n",
            "Epoch 18/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4442 - accuracy: 0.5911 - val_loss: 2.1575 - val_accuracy: 0.3958\n",
            "Epoch 19/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.3683 - accuracy: 0.6007 - val_loss: 2.0350 - val_accuracy: 0.3403\n",
            "Epoch 20/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4056 - accuracy: 0.5833 - val_loss: 1.8515 - val_accuracy: 0.4444\n",
            "Epoch 21/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4077 - accuracy: 0.5868 - val_loss: 1.7900 - val_accuracy: 0.4306\n",
            "Epoch 22/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.3589 - accuracy: 0.6189 - val_loss: 1.8461 - val_accuracy: 0.4583\n",
            "Epoch 23/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.3872 - accuracy: 0.6215 - val_loss: 1.6712 - val_accuracy: 0.5000\n",
            "Epoch 24/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 1.3028 - accuracy: 0.6389 - val_loss: 1.5391 - val_accuracy: 0.6042\n",
            "Epoch 25/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.2700 - accuracy: 0.6380 - val_loss: 1.6587 - val_accuracy: 0.5278\n",
            "Epoch 26/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2031 - accuracy: 0.6806 - val_loss: 1.6743 - val_accuracy: 0.4861\n",
            "Epoch 27/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.2317 - accuracy: 0.6484 - val_loss: 25.9000 - val_accuracy: 0.1944\n",
            "Epoch 28/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 3.4191 - accuracy: 0.5425 - val_loss: 1.9576 - val_accuracy: 0.5139\n",
            "Epoch 29/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.3915 - accuracy: 0.6259 - val_loss: 1.5778 - val_accuracy: 0.5694\n",
            "Epoch 30/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.2891 - accuracy: 0.6632 - val_loss: 1.6498 - val_accuracy: 0.5000\n",
            "Epoch 31/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.2017 - accuracy: 0.6849 - val_loss: 1.6239 - val_accuracy: 0.5417\n",
            "Epoch 32/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.2116 - accuracy: 0.6832 - val_loss: 1.6311 - val_accuracy: 0.5556\n",
            "Epoch 33/98\n",
            "19/19 [==============================] - 16s 836ms/step - loss: 1.1553 - accuracy: 0.7057 - val_loss: 1.6349 - val_accuracy: 0.5556\n",
            "Epoch 34/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.1177 - accuracy: 0.7396 - val_loss: 1.5303 - val_accuracy: 0.5556\n",
            "Epoch 35/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 1.0996 - accuracy: 0.7196 - val_loss: 1.5076 - val_accuracy: 0.5833\n",
            "Epoch 36/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.0926 - accuracy: 0.7188 - val_loss: 1.7305 - val_accuracy: 0.4931\n",
            "Epoch 37/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.1144 - accuracy: 0.7118 - val_loss: 1.7213 - val_accuracy: 0.4722\n",
            "Epoch 38/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.1030 - accuracy: 0.7378 - val_loss: 1.7502 - val_accuracy: 0.4583\n",
            "Epoch 39/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 1.0672 - accuracy: 0.7431 - val_loss: 1.6020 - val_accuracy: 0.5694\n",
            "Epoch 40/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.1099 - accuracy: 0.7274 - val_loss: 1.5480 - val_accuracy: 0.5556\n",
            "Epoch 41/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.2170 - accuracy: 0.7118 - val_loss: 2.2938 - val_accuracy: 0.5139\n",
            "Epoch 42/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 1.1276 - accuracy: 0.7361 - val_loss: 2.8860 - val_accuracy: 0.4167\n",
            "Epoch 43/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.0253 - accuracy: 0.7717 - val_loss: 1.7946 - val_accuracy: 0.5625\n",
            "Epoch 44/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.0261 - accuracy: 0.7665 - val_loss: 1.4954 - val_accuracy: 0.5833\n",
            "Epoch 45/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.0093 - accuracy: 0.7656 - val_loss: 1.7952 - val_accuracy: 0.4722\n",
            "Epoch 46/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.9691 - accuracy: 0.7630 - val_loss: 1.6079 - val_accuracy: 0.5417\n",
            "Epoch 47/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0153 - accuracy: 0.7743 - val_loss: 1.4738 - val_accuracy: 0.6042\n",
            "Epoch 48/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 1.1339 - accuracy: 0.7405 - val_loss: 1.6049 - val_accuracy: 0.6250\n",
            "Epoch 49/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.0670 - accuracy: 0.7752 - val_loss: 1.7257 - val_accuracy: 0.5694\n",
            "Epoch 50/98\n",
            "19/19 [==============================] - 15s 802ms/step - loss: 1.0738 - accuracy: 0.7439 - val_loss: 1.5867 - val_accuracy: 0.5972\n",
            "Epoch 51/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 0.9873 - accuracy: 0.7917 - val_loss: 1.9202 - val_accuracy: 0.4792\n",
            "Epoch 52/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 0.9785 - accuracy: 0.7925 - val_loss: 1.6011 - val_accuracy: 0.5139\n",
            "Epoch 53/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 0.9489 - accuracy: 0.7917 - val_loss: 1.6480 - val_accuracy: 0.5417\n",
            "Epoch 54/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.9461 - accuracy: 0.7917 - val_loss: 1.7553 - val_accuracy: 0.5139\n",
            "Epoch 55/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.9131 - accuracy: 0.8003 - val_loss: 1.4711 - val_accuracy: 0.5833\n",
            "Epoch 56/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.9084 - accuracy: 0.7882 - val_loss: 1.5299 - val_accuracy: 0.5972\n",
            "Epoch 57/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8945 - accuracy: 0.8021 - val_loss: 2.0552 - val_accuracy: 0.5278\n",
            "Epoch 58/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.8806 - accuracy: 0.8047 - val_loss: 1.6698 - val_accuracy: 0.5764\n",
            "Epoch 59/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 0.8488 - accuracy: 0.8273 - val_loss: 1.4381 - val_accuracy: 0.6319\n",
            "Epoch 60/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.9391 - accuracy: 0.7847 - val_loss: 1.5705 - val_accuracy: 0.6042\n",
            "Epoch 61/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 0.8671 - accuracy: 0.8142 - val_loss: 1.5321 - val_accuracy: 0.5694\n",
            "Epoch 62/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 0.8197 - accuracy: 0.8290 - val_loss: 1.7069 - val_accuracy: 0.5972\n",
            "Epoch 63/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 0.8218 - accuracy: 0.8377 - val_loss: 1.5205 - val_accuracy: 0.5764\n",
            "Epoch 64/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.8932 - accuracy: 0.8116 - val_loss: 1.4467 - val_accuracy: 0.6389\n",
            "Epoch 65/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 0.8904 - accuracy: 0.8012 - val_loss: 1.7494 - val_accuracy: 0.5556\n",
            "Epoch 66/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8302 - accuracy: 0.8325 - val_loss: 1.6201 - val_accuracy: 0.5833\n",
            "Epoch 67/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.8288 - accuracy: 0.8168 - val_loss: 1.7972 - val_accuracy: 0.5139\n",
            "Epoch 68/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.7768 - accuracy: 0.8420 - val_loss: 1.6901 - val_accuracy: 0.5556\n",
            "Epoch 69/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.7833 - accuracy: 0.8429 - val_loss: 1.5051 - val_accuracy: 0.5347\n",
            "Epoch 70/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 0.8516 - accuracy: 0.8255 - val_loss: 1.5858 - val_accuracy: 0.6181\n",
            "Epoch 71/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8510 - accuracy: 0.8281 - val_loss: 1.7182 - val_accuracy: 0.5556\n",
            "Epoch 72/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.8042 - accuracy: 0.8438 - val_loss: 1.5437 - val_accuracy: 0.5972\n",
            "Epoch 73/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.7813 - accuracy: 0.8524 - val_loss: 1.3969 - val_accuracy: 0.6597\n",
            "Epoch 74/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 0.8310 - accuracy: 0.8351 - val_loss: 1.5806 - val_accuracy: 0.6042\n",
            "Epoch 75/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8048 - accuracy: 0.8342 - val_loss: 1.4045 - val_accuracy: 0.6597\n",
            "Epoch 76/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 0.7652 - accuracy: 0.8533 - val_loss: 1.4032 - val_accuracy: 0.6181\n",
            "Epoch 77/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.7526 - accuracy: 0.8490 - val_loss: 1.3127 - val_accuracy: 0.6944\n",
            "Epoch 78/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.8219 - accuracy: 0.8455 - val_loss: 1.6227 - val_accuracy: 0.5833\n",
            "Epoch 79/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8263 - accuracy: 0.8542 - val_loss: 1.7891 - val_accuracy: 0.5694\n",
            "Epoch 80/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.8784 - accuracy: 0.8194 - val_loss: 1.8585 - val_accuracy: 0.5625\n",
            "Epoch 81/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8546 - accuracy: 0.8403 - val_loss: 1.6073 - val_accuracy: 0.5972\n",
            "Epoch 82/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8139 - accuracy: 0.8464 - val_loss: 1.6778 - val_accuracy: 0.5694\n",
            "Epoch 83/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 0.8034 - accuracy: 0.8602 - val_loss: 1.3757 - val_accuracy: 0.6528\n",
            "Epoch 84/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 0.8373 - accuracy: 0.8333 - val_loss: 1.5234 - val_accuracy: 0.6528\n",
            "Epoch 85/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8141 - accuracy: 0.8533 - val_loss: 1.4368 - val_accuracy: 0.6389\n",
            "Epoch 86/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.8186 - accuracy: 0.8351 - val_loss: 1.4256 - val_accuracy: 0.6389\n",
            "Epoch 87/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.7846 - accuracy: 0.8411 - val_loss: 1.7942 - val_accuracy: 0.5417\n",
            "Epoch 88/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 0.8334 - accuracy: 0.8290 - val_loss: 1.3915 - val_accuracy: 0.6042\n",
            "Epoch 89/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.9212 - accuracy: 0.8134 - val_loss: 1.9133 - val_accuracy: 0.5417\n",
            "Epoch 90/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 0.8815 - accuracy: 0.8385 - val_loss: 1.7381 - val_accuracy: 0.5417\n",
            "Epoch 91/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 0.8306 - accuracy: 0.8585 - val_loss: 1.5965 - val_accuracy: 0.6042\n",
            "Epoch 92/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.8755 - accuracy: 0.8385 - val_loss: 1.6750 - val_accuracy: 0.5694\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.3919 - accuracy: 0.6389\n",
            "Test loss of the model is -  1.391920804977417\n",
            "Test accuracy of the model is -  63.88888955116272 %\n",
            "EPOCHS:  96\n",
            "BATCH_SIZE:  42\n",
            "LEARNING_RATE:  0.003911635292154655\n",
            "Epoch 1/96\n",
            "28/28 [==============================] - 22s 555ms/step - loss: 143.3983 - accuracy: 0.2092 - val_loss: 3.5895 - val_accuracy: 0.2153\n",
            "Epoch 2/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 2.5220 - accuracy: 0.2873 - val_loss: 2.6567 - val_accuracy: 0.2639\n",
            "Epoch 3/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 2.0728 - accuracy: 0.3316 - val_loss: 2.1791 - val_accuracy: 0.3472\n",
            "Epoch 4/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.9103 - accuracy: 0.3681 - val_loss: 1.9216 - val_accuracy: 0.4028\n",
            "Epoch 5/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.8767 - accuracy: 0.3863 - val_loss: 2.1478 - val_accuracy: 0.3681\n",
            "Epoch 6/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.8253 - accuracy: 0.4175 - val_loss: 1.9600 - val_accuracy: 0.3542\n",
            "Epoch 7/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.7304 - accuracy: 0.4557 - val_loss: 2.1021 - val_accuracy: 0.3472\n",
            "Epoch 8/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.6165 - accuracy: 0.4913 - val_loss: 1.7270 - val_accuracy: 0.4931\n",
            "Epoch 9/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.7080 - accuracy: 0.4714 - val_loss: 1.9339 - val_accuracy: 0.3681\n",
            "Epoch 10/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.6048 - accuracy: 0.4991 - val_loss: 1.8761 - val_accuracy: 0.3542\n",
            "Epoch 11/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.6174 - accuracy: 0.5000 - val_loss: 1.8557 - val_accuracy: 0.4097\n",
            "Epoch 12/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.5787 - accuracy: 0.4974 - val_loss: 1.8285 - val_accuracy: 0.4722\n",
            "Epoch 13/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 1.5679 - accuracy: 0.5321 - val_loss: 1.8035 - val_accuracy: 0.5069\n",
            "Epoch 14/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.6542 - accuracy: 0.5191 - val_loss: 2.1364 - val_accuracy: 0.3958\n",
            "Epoch 15/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.5507 - accuracy: 0.5469 - val_loss: 1.9340 - val_accuracy: 0.4514\n",
            "Epoch 16/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.5384 - accuracy: 0.5486 - val_loss: 1.9638 - val_accuracy: 0.3403\n",
            "Epoch 17/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.4934 - accuracy: 0.5842 - val_loss: 1.7315 - val_accuracy: 0.5625\n",
            "Epoch 18/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.4991 - accuracy: 0.5773 - val_loss: 1.8129 - val_accuracy: 0.4931\n",
            "Epoch 19/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.4353 - accuracy: 0.6033 - val_loss: 1.7636 - val_accuracy: 0.4792\n",
            "Epoch 20/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.4014 - accuracy: 0.6189 - val_loss: 1.6294 - val_accuracy: 0.5833\n",
            "Epoch 21/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.4875 - accuracy: 0.5868 - val_loss: 1.9672 - val_accuracy: 0.4931\n",
            "Epoch 22/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.4338 - accuracy: 0.6024 - val_loss: 1.6321 - val_accuracy: 0.5625\n",
            "Epoch 23/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.3765 - accuracy: 0.6302 - val_loss: 1.7240 - val_accuracy: 0.4583\n",
            "Epoch 24/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.2978 - accuracy: 0.6311 - val_loss: 1.5054 - val_accuracy: 0.6042\n",
            "Epoch 25/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.3058 - accuracy: 0.6215 - val_loss: 1.7341 - val_accuracy: 0.5278\n",
            "Epoch 26/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.3769 - accuracy: 0.6137 - val_loss: 1.7408 - val_accuracy: 0.4931\n",
            "Epoch 27/96\n",
            "28/28 [==============================] - 15s 535ms/step - loss: 1.3639 - accuracy: 0.6345 - val_loss: 1.5163 - val_accuracy: 0.6458\n",
            "Epoch 28/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 1.2671 - accuracy: 0.6736 - val_loss: 1.6614 - val_accuracy: 0.5486\n",
            "Epoch 29/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.2939 - accuracy: 0.6432 - val_loss: 1.7815 - val_accuracy: 0.4167\n",
            "Epoch 30/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.3927 - accuracy: 0.6302 - val_loss: 2.2173 - val_accuracy: 0.3194\n",
            "Epoch 31/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.3225 - accuracy: 0.6484 - val_loss: 1.8698 - val_accuracy: 0.4792\n",
            "Epoch 32/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 1.3528 - accuracy: 0.6580 - val_loss: 1.6427 - val_accuracy: 0.5139\n",
            "Epoch 33/96\n",
            "28/28 [==============================] - 15s 536ms/step - loss: 1.3278 - accuracy: 0.6441 - val_loss: 1.6164 - val_accuracy: 0.5486\n",
            "Epoch 34/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.2988 - accuracy: 0.6719 - val_loss: 1.5484 - val_accuracy: 0.6319\n",
            "Epoch 35/96\n",
            "28/28 [==============================] - 15s 537ms/step - loss: 1.2322 - accuracy: 0.6762 - val_loss: 1.6821 - val_accuracy: 0.5486\n",
            "Epoch 36/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.2222 - accuracy: 0.6727 - val_loss: 1.6915 - val_accuracy: 0.5347\n",
            "Epoch 37/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.2091 - accuracy: 0.6927 - val_loss: 1.5761 - val_accuracy: 0.5625\n",
            "Epoch 38/96\n",
            "28/28 [==============================] - 15s 538ms/step - loss: 1.2018 - accuracy: 0.6918 - val_loss: 1.5835 - val_accuracy: 0.6042\n",
            "Epoch 39/96\n",
            "28/28 [==============================] - 15s 539ms/step - loss: 1.2241 - accuracy: 0.6858 - val_loss: 1.6564 - val_accuracy: 0.6181\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 1.6281 - accuracy: 0.4931\n",
            "Test loss of the model is -  1.6281375885009766\n",
            "Test accuracy of the model is -  49.30555522441864 %\n",
            "EPOCHS:  90\n",
            "BATCH_SIZE:  36\n",
            "LEARNING_RATE:  0.004183665066564939\n",
            "Epoch 1/90\n",
            "32/32 [==============================] - 20s 480ms/step - loss: 29.5813 - accuracy: 0.2135 - val_loss: 3.1218 - val_accuracy: 0.1250\n",
            "Epoch 2/90\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 2.3632 - accuracy: 0.3099 - val_loss: 2.3274 - val_accuracy: 0.2917\n",
            "Epoch 3/90\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 2.0558 - accuracy: 0.3498 - val_loss: 3.0117 - val_accuracy: 0.1667\n",
            "Epoch 4/90\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.9024 - accuracy: 0.3576 - val_loss: 1.9434 - val_accuracy: 0.2917\n",
            "Epoch 5/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.9817 - accuracy: 0.3559 - val_loss: 2.0366 - val_accuracy: 0.3403\n",
            "Epoch 6/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 3.6146 - accuracy: 0.3802 - val_loss: 2.0152 - val_accuracy: 0.3056\n",
            "Epoch 7/90\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.9256 - accuracy: 0.3490 - val_loss: 1.8700 - val_accuracy: 0.3681\n",
            "Epoch 8/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7706 - accuracy: 0.3915 - val_loss: 1.8622 - val_accuracy: 0.3472\n",
            "Epoch 9/90\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7359 - accuracy: 0.4080 - val_loss: 1.8449 - val_accuracy: 0.4236\n",
            "Epoch 10/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.8123 - accuracy: 0.4184 - val_loss: 1.9314 - val_accuracy: 0.4167\n",
            "Epoch 11/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.8125 - accuracy: 0.4028 - val_loss: 1.9127 - val_accuracy: 0.3542\n",
            "Epoch 12/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7392 - accuracy: 0.4418 - val_loss: 1.8370 - val_accuracy: 0.4583\n",
            "Epoch 13/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7478 - accuracy: 0.4245 - val_loss: 1.7705 - val_accuracy: 0.4444\n",
            "Epoch 14/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6970 - accuracy: 0.4557 - val_loss: 1.7852 - val_accuracy: 0.4375\n",
            "Epoch 15/90\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.6741 - accuracy: 0.4627 - val_loss: 1.9983 - val_accuracy: 0.2639\n",
            "Epoch 16/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7153 - accuracy: 0.4540 - val_loss: 1.9889 - val_accuracy: 0.3542\n",
            "Epoch 17/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7261 - accuracy: 0.4635 - val_loss: 2.0084 - val_accuracy: 0.3542\n",
            "Epoch 18/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6975 - accuracy: 0.4705 - val_loss: 1.8155 - val_accuracy: 0.3958\n",
            "Epoch 19/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6080 - accuracy: 0.4696 - val_loss: 1.6839 - val_accuracy: 0.4722\n",
            "Epoch 20/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6618 - accuracy: 0.4766 - val_loss: 1.9464 - val_accuracy: 0.3958\n",
            "Epoch 21/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7044 - accuracy: 0.4861 - val_loss: 2.0085 - val_accuracy: 0.4236\n",
            "Epoch 22/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6858 - accuracy: 0.4774 - val_loss: 1.8261 - val_accuracy: 0.4514\n",
            "Epoch 23/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6321 - accuracy: 0.5200 - val_loss: 2.0212 - val_accuracy: 0.2917\n",
            "Epoch 24/90\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.6735 - accuracy: 0.4913 - val_loss: 2.0809 - val_accuracy: 0.3958\n",
            "Epoch 25/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6296 - accuracy: 0.4627 - val_loss: 1.8114 - val_accuracy: 0.4306\n",
            "Epoch 26/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.5865 - accuracy: 0.5234 - val_loss: 1.7462 - val_accuracy: 0.5000\n",
            "Epoch 27/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6338 - accuracy: 0.5130 - val_loss: 1.8155 - val_accuracy: 0.4931\n",
            "Epoch 28/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5703 - accuracy: 0.5148 - val_loss: 1.7781 - val_accuracy: 0.4583\n",
            "Epoch 29/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.5753 - accuracy: 0.5104 - val_loss: 1.7763 - val_accuracy: 0.4444\n",
            "Epoch 30/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5819 - accuracy: 0.5200 - val_loss: 2.5312 - val_accuracy: 0.2917\n",
            "Epoch 31/90\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.6023 - accuracy: 0.5226 - val_loss: 1.7693 - val_accuracy: 0.5139\n",
            "Epoch 32/90\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5097 - accuracy: 0.5425 - val_loss: 1.6971 - val_accuracy: 0.5000\n",
            "Epoch 33/90\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.5656 - accuracy: 0.5347 - val_loss: 1.8419 - val_accuracy: 0.4722\n",
            "Epoch 34/90\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7009 - accuracy: 0.4800 - val_loss: 2.4691 - val_accuracy: 0.3264\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.8969 - accuracy: 0.3819\n",
            "Test loss of the model is -  1.896873950958252\n",
            "Test accuracy of the model is -  38.19444477558136 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  51\n",
            "LEARNING_RATE:  0.0016647160917598715\n",
            "Epoch 1/85\n",
            "23/23 [==============================] - 21s 681ms/step - loss: 13.9651 - accuracy: 0.2153 - val_loss: 2.6281 - val_accuracy: 0.2917\n",
            "Epoch 2/85\n",
            "23/23 [==============================] - 15s 662ms/step - loss: 2.3620 - accuracy: 0.3238 - val_loss: 2.4406 - val_accuracy: 0.2361\n",
            "Epoch 3/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 2.0726 - accuracy: 0.3872 - val_loss: 2.2001 - val_accuracy: 0.2847\n",
            "Epoch 4/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.8291 - accuracy: 0.4427 - val_loss: 1.9838 - val_accuracy: 0.4514\n",
            "Epoch 5/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.6987 - accuracy: 0.4740 - val_loss: 1.9386 - val_accuracy: 0.3889\n",
            "Epoch 6/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.6327 - accuracy: 0.4783 - val_loss: 1.8508 - val_accuracy: 0.4167\n",
            "Epoch 7/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.5525 - accuracy: 0.5234 - val_loss: 1.9431 - val_accuracy: 0.3750\n",
            "Epoch 8/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 1.4961 - accuracy: 0.5399 - val_loss: 1.7173 - val_accuracy: 0.5764\n",
            "Epoch 9/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 1.4340 - accuracy: 0.5495 - val_loss: 1.7522 - val_accuracy: 0.4792\n",
            "Epoch 10/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.3605 - accuracy: 0.5729 - val_loss: 1.6792 - val_accuracy: 0.4931\n",
            "Epoch 11/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.3244 - accuracy: 0.6085 - val_loss: 1.9153 - val_accuracy: 0.3403\n",
            "Epoch 12/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.2215 - accuracy: 0.6432 - val_loss: 1.5559 - val_accuracy: 0.5764\n",
            "Epoch 13/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.2467 - accuracy: 0.6293 - val_loss: 1.4510 - val_accuracy: 0.6250\n",
            "Epoch 14/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.2614 - accuracy: 0.6250 - val_loss: 1.7013 - val_accuracy: 0.4583\n",
            "Epoch 15/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.1703 - accuracy: 0.6693 - val_loss: 1.5424 - val_accuracy: 0.5486\n",
            "Epoch 16/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.1700 - accuracy: 0.6589 - val_loss: 1.7244 - val_accuracy: 0.4097\n",
            "Epoch 17/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.0312 - accuracy: 0.7066 - val_loss: 1.4520 - val_accuracy: 0.5833\n",
            "Epoch 18/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 0.9942 - accuracy: 0.7309 - val_loss: 1.4921 - val_accuracy: 0.5347\n",
            "Epoch 19/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.0245 - accuracy: 0.7170 - val_loss: 1.3237 - val_accuracy: 0.6250\n",
            "Epoch 20/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.0118 - accuracy: 0.7335 - val_loss: 1.3069 - val_accuracy: 0.6875\n",
            "Epoch 21/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.0480 - accuracy: 0.7474 - val_loss: 1.2905 - val_accuracy: 0.6319\n",
            "Epoch 22/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.0685 - accuracy: 0.7153 - val_loss: 1.6173 - val_accuracy: 0.5347\n",
            "Epoch 23/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.0058 - accuracy: 0.7474 - val_loss: 1.3402 - val_accuracy: 0.6319\n",
            "Epoch 24/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.9738 - accuracy: 0.7439 - val_loss: 1.2424 - val_accuracy: 0.7153\n",
            "Epoch 25/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.9642 - accuracy: 0.7569 - val_loss: 1.1829 - val_accuracy: 0.6944\n",
            "Epoch 26/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 0.9131 - accuracy: 0.7795 - val_loss: 1.4408 - val_accuracy: 0.6042\n",
            "Epoch 27/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.8502 - accuracy: 0.8142 - val_loss: 1.2967 - val_accuracy: 0.6111\n",
            "Epoch 28/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.8374 - accuracy: 0.7995 - val_loss: 1.4504 - val_accuracy: 0.6181\n",
            "Epoch 29/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.7998 - accuracy: 0.8099 - val_loss: 1.3210 - val_accuracy: 0.6181\n",
            "Epoch 30/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.8480 - accuracy: 0.8003 - val_loss: 1.4460 - val_accuracy: 0.5903\n",
            "Epoch 31/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.8975 - accuracy: 0.7847 - val_loss: 1.0987 - val_accuracy: 0.7639\n",
            "Epoch 32/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.9354 - accuracy: 0.7734 - val_loss: 1.3254 - val_accuracy: 0.6181\n",
            "Epoch 33/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.8442 - accuracy: 0.8186 - val_loss: 1.3233 - val_accuracy: 0.6806\n",
            "Epoch 34/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.8216 - accuracy: 0.8168 - val_loss: 1.2594 - val_accuracy: 0.6389\n",
            "Epoch 35/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.7580 - accuracy: 0.8385 - val_loss: 1.2271 - val_accuracy: 0.6597\n",
            "Epoch 36/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7361 - accuracy: 0.8429 - val_loss: 1.0807 - val_accuracy: 0.7361\n",
            "Epoch 37/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6770 - accuracy: 0.8663 - val_loss: 1.2120 - val_accuracy: 0.6528\n",
            "Epoch 38/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.6718 - accuracy: 0.8585 - val_loss: 1.3674 - val_accuracy: 0.6528\n",
            "Epoch 39/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6993 - accuracy: 0.8472 - val_loss: 1.2208 - val_accuracy: 0.7014\n",
            "Epoch 40/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7277 - accuracy: 0.8455 - val_loss: 1.1635 - val_accuracy: 0.7153\n",
            "Epoch 41/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6741 - accuracy: 0.8715 - val_loss: 1.1531 - val_accuracy: 0.6806\n",
            "Epoch 42/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7187 - accuracy: 0.8516 - val_loss: 1.2761 - val_accuracy: 0.6944\n",
            "Epoch 43/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.6774 - accuracy: 0.8672 - val_loss: 1.1239 - val_accuracy: 0.7292\n",
            "Epoch 44/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6050 - accuracy: 0.8837 - val_loss: 1.1271 - val_accuracy: 0.7153\n",
            "Epoch 45/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5985 - accuracy: 0.8811 - val_loss: 1.2466 - val_accuracy: 0.6875\n",
            "Epoch 46/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5907 - accuracy: 0.8776 - val_loss: 1.2841 - val_accuracy: 0.7222\n",
            "Epoch 47/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.5900 - accuracy: 0.8967 - val_loss: 1.1608 - val_accuracy: 0.6736\n",
            "Epoch 48/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.5762 - accuracy: 0.8898 - val_loss: 1.1799 - val_accuracy: 0.6736\n",
            "Epoch 49/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6039 - accuracy: 0.8793 - val_loss: 1.4644 - val_accuracy: 0.6181\n",
            "Epoch 50/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6183 - accuracy: 0.8707 - val_loss: 1.4780 - val_accuracy: 0.5972\n",
            "Epoch 51/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.6524 - accuracy: 0.8655 - val_loss: 1.2236 - val_accuracy: 0.7292\n",
            "5/5 [==============================] - 1s 116ms/step - loss: 1.4095 - accuracy: 0.6528\n",
            "Test loss of the model is -  1.4094834327697754\n",
            "Test accuracy of the model is -  65.27777910232544 %\n",
            "EPOCHS:  80\n",
            "BATCH_SIZE:  39\n",
            "LEARNING_RATE:  0.0018805124864760539\n",
            "Epoch 1/80\n",
            "30/30 [==============================] - 21s 504ms/step - loss: 21.7874 - accuracy: 0.2266 - val_loss: 3.2982 - val_accuracy: 0.2708\n",
            "Epoch 2/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 2.2710 - accuracy: 0.3203 - val_loss: 2.2643 - val_accuracy: 0.3125\n",
            "Epoch 3/80\n",
            "30/30 [==============================] - 15s 496ms/step - loss: 1.9422 - accuracy: 0.3967 - val_loss: 2.1749 - val_accuracy: 0.2986\n",
            "Epoch 4/80\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 1.8553 - accuracy: 0.3854 - val_loss: 1.9078 - val_accuracy: 0.4167\n",
            "Epoch 5/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.6865 - accuracy: 0.4523 - val_loss: 1.8009 - val_accuracy: 0.4583\n",
            "Epoch 6/80\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.6252 - accuracy: 0.4783 - val_loss: 1.7970 - val_accuracy: 0.4375\n",
            "Epoch 7/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.5615 - accuracy: 0.5165 - val_loss: 2.0777 - val_accuracy: 0.4097\n",
            "Epoch 8/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.5503 - accuracy: 0.5052 - val_loss: 1.7337 - val_accuracy: 0.4931\n",
            "Epoch 9/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.5457 - accuracy: 0.5269 - val_loss: 1.8314 - val_accuracy: 0.4444\n",
            "Epoch 10/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.4368 - accuracy: 0.5391 - val_loss: 1.7936 - val_accuracy: 0.4444\n",
            "Epoch 11/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.3551 - accuracy: 0.5929 - val_loss: 1.5790 - val_accuracy: 0.5069\n",
            "Epoch 12/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.2319 - accuracy: 0.6345 - val_loss: 1.5255 - val_accuracy: 0.5417\n",
            "Epoch 13/80\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.2804 - accuracy: 0.6189 - val_loss: 1.6981 - val_accuracy: 0.4236\n",
            "Epoch 14/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.2254 - accuracy: 0.6345 - val_loss: 1.5166 - val_accuracy: 0.5486\n",
            "Epoch 15/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.1970 - accuracy: 0.6771 - val_loss: 1.5859 - val_accuracy: 0.5417\n",
            "Epoch 16/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.2236 - accuracy: 0.6293 - val_loss: 1.4825 - val_accuracy: 0.5694\n",
            "Epoch 17/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.1816 - accuracy: 0.6832 - val_loss: 1.4952 - val_accuracy: 0.5694\n",
            "Epoch 18/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.1725 - accuracy: 0.6849 - val_loss: 1.5098 - val_accuracy: 0.5833\n",
            "Epoch 19/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.1988 - accuracy: 0.6866 - val_loss: 1.7267 - val_accuracy: 0.4931\n",
            "Epoch 20/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.1372 - accuracy: 0.6962 - val_loss: 1.6060 - val_accuracy: 0.5694\n",
            "Epoch 21/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.0814 - accuracy: 0.7170 - val_loss: 1.4792 - val_accuracy: 0.5139\n",
            "Epoch 22/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.0783 - accuracy: 0.7196 - val_loss: 1.3753 - val_accuracy: 0.6319\n",
            "Epoch 23/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0392 - accuracy: 0.7396 - val_loss: 1.3959 - val_accuracy: 0.6111\n",
            "Epoch 24/80\n",
            "30/30 [==============================] - 15s 494ms/step - loss: 1.0272 - accuracy: 0.7370 - val_loss: 1.4270 - val_accuracy: 0.6042\n",
            "Epoch 25/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.0183 - accuracy: 0.7448 - val_loss: 1.3880 - val_accuracy: 0.6667\n",
            "Epoch 26/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.9451 - accuracy: 0.7674 - val_loss: 1.4089 - val_accuracy: 0.5903\n",
            "Epoch 27/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.9908 - accuracy: 0.7682 - val_loss: 1.3041 - val_accuracy: 0.6181\n",
            "Epoch 28/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.9297 - accuracy: 0.7865 - val_loss: 1.4278 - val_accuracy: 0.6181\n",
            "Epoch 29/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.9044 - accuracy: 0.7873 - val_loss: 1.3994 - val_accuracy: 0.6528\n",
            "Epoch 30/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.8602 - accuracy: 0.7917 - val_loss: 1.4242 - val_accuracy: 0.6042\n",
            "Epoch 31/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.8528 - accuracy: 0.8108 - val_loss: 1.3063 - val_accuracy: 0.6389\n",
            "Epoch 32/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.8980 - accuracy: 0.7734 - val_loss: 1.4165 - val_accuracy: 0.6111\n",
            "Epoch 33/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.8560 - accuracy: 0.8064 - val_loss: 1.4151 - val_accuracy: 0.6111\n",
            "Epoch 34/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.9478 - accuracy: 0.7882 - val_loss: 1.4582 - val_accuracy: 0.5764\n",
            "Epoch 35/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.9433 - accuracy: 0.7812 - val_loss: 1.7610 - val_accuracy: 0.5278\n",
            "Epoch 36/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.8737 - accuracy: 0.8203 - val_loss: 1.3971 - val_accuracy: 0.6111\n",
            "Epoch 37/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.8217 - accuracy: 0.8281 - val_loss: 1.3493 - val_accuracy: 0.6528\n",
            "Epoch 38/80\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.8286 - accuracy: 0.8125 - val_loss: 1.4732 - val_accuracy: 0.5625\n",
            "Epoch 39/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.8208 - accuracy: 0.8142 - val_loss: 1.6717 - val_accuracy: 0.5625\n",
            "Epoch 40/80\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.7539 - accuracy: 0.8585 - val_loss: 1.4950 - val_accuracy: 0.6667\n",
            "Epoch 41/80\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.8010 - accuracy: 0.8403 - val_loss: 1.4528 - val_accuracy: 0.6250\n",
            "Epoch 42/80\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.7738 - accuracy: 0.8194 - val_loss: 1.4737 - val_accuracy: 0.6181\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 1.6113 - accuracy: 0.5556\n",
            "Test loss of the model is -  1.611314058303833\n",
            "Test accuracy of the model is -  55.55555820465088 %\n",
            "EPOCHS:  98\n",
            "BATCH_SIZE:  62\n",
            "LEARNING_RATE:  0.0032872209120587683\n",
            "Epoch 1/98\n",
            "19/19 [==============================] - 22s 871ms/step - loss: 69.5260 - accuracy: 0.1701 - val_loss: 3.0710 - val_accuracy: 0.2569\n",
            "Epoch 2/98\n",
            "19/19 [==============================] - 16s 847ms/step - loss: 2.8129 - accuracy: 0.2274 - val_loss: 2.4075 - val_accuracy: 0.3056\n",
            "Epoch 3/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 2.2180 - accuracy: 0.3212 - val_loss: 2.1602 - val_accuracy: 0.3472\n",
            "Epoch 4/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.9615 - accuracy: 0.3785 - val_loss: 2.0232 - val_accuracy: 0.3333\n",
            "Epoch 5/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.8209 - accuracy: 0.3993 - val_loss: 2.0260 - val_accuracy: 0.3194\n",
            "Epoch 6/98\n",
            "19/19 [==============================] - 15s 809ms/step - loss: 1.7516 - accuracy: 0.4149 - val_loss: 2.0141 - val_accuracy: 0.2847\n",
            "Epoch 7/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.6453 - accuracy: 0.4453 - val_loss: 1.8759 - val_accuracy: 0.3958\n",
            "Epoch 8/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.6145 - accuracy: 0.4696 - val_loss: 1.8862 - val_accuracy: 0.3403\n",
            "Epoch 9/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.6320 - accuracy: 0.4757 - val_loss: 1.9075 - val_accuracy: 0.4722\n",
            "Epoch 10/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.5735 - accuracy: 0.5026 - val_loss: 1.7859 - val_accuracy: 0.4444\n",
            "Epoch 11/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4968 - accuracy: 0.5286 - val_loss: 1.8196 - val_accuracy: 0.4861\n",
            "Epoch 12/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4816 - accuracy: 0.5113 - val_loss: 1.5849 - val_accuracy: 0.5486\n",
            "Epoch 13/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.5113 - accuracy: 0.5382 - val_loss: 2.0490 - val_accuracy: 0.4306\n",
            "Epoch 14/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.4803 - accuracy: 0.5512 - val_loss: 1.5471 - val_accuracy: 0.5764\n",
            "Epoch 15/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.4535 - accuracy: 0.5434 - val_loss: 1.6365 - val_accuracy: 0.5694\n",
            "Epoch 16/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.3917 - accuracy: 0.5738 - val_loss: 1.6827 - val_accuracy: 0.4861\n",
            "Epoch 17/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.3549 - accuracy: 0.5998 - val_loss: 1.6289 - val_accuracy: 0.5347\n",
            "Epoch 18/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.3003 - accuracy: 0.6345 - val_loss: 1.7888 - val_accuracy: 0.4583\n",
            "Epoch 19/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.3479 - accuracy: 0.6042 - val_loss: 1.8077 - val_accuracy: 0.3889\n",
            "Epoch 20/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.3399 - accuracy: 0.6128 - val_loss: 1.7398 - val_accuracy: 0.4167\n",
            "Epoch 21/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.3861 - accuracy: 0.6076 - val_loss: 1.5996 - val_accuracy: 0.5833\n",
            "Epoch 22/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.3503 - accuracy: 0.6163 - val_loss: 1.6686 - val_accuracy: 0.5000\n",
            "Epoch 23/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.3198 - accuracy: 0.6285 - val_loss: 1.6363 - val_accuracy: 0.5833\n",
            "Epoch 24/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.2752 - accuracy: 0.6589 - val_loss: 1.6835 - val_accuracy: 0.5069\n",
            "Epoch 25/98\n",
            "19/19 [==============================] - 15s 810ms/step - loss: 1.2502 - accuracy: 0.6484 - val_loss: 1.6222 - val_accuracy: 0.5556\n",
            "Epoch 26/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.2281 - accuracy: 0.6606 - val_loss: 1.5999 - val_accuracy: 0.5556\n",
            "Epoch 27/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.1994 - accuracy: 0.6693 - val_loss: 1.5452 - val_accuracy: 0.6319\n",
            "Epoch 28/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.1531 - accuracy: 0.6988 - val_loss: 1.4677 - val_accuracy: 0.6389\n",
            "Epoch 29/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 2.2443 - accuracy: 0.6753 - val_loss: 2.0384 - val_accuracy: 0.4306\n",
            "Epoch 30/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 19.0271 - accuracy: 0.4575 - val_loss: 3.2120 - val_accuracy: 0.4375\n",
            "Epoch 31/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 93.6195 - accuracy: 0.4158 - val_loss: 4.4034 - val_accuracy: 0.4097\n",
            "Epoch 32/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 2.7420 - accuracy: 0.5017 - val_loss: 2.7709 - val_accuracy: 0.5069\n",
            "Epoch 33/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 1.7440 - accuracy: 0.5747 - val_loss: 1.8209 - val_accuracy: 0.5278\n",
            "Epoch 34/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 1.4381 - accuracy: 0.6302 - val_loss: 1.7401 - val_accuracy: 0.5347\n",
            "Epoch 35/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.2730 - accuracy: 0.6736 - val_loss: 1.6337 - val_accuracy: 0.4792\n",
            "Epoch 36/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.1665 - accuracy: 0.6988 - val_loss: 1.9678 - val_accuracy: 0.4167\n",
            "Epoch 37/98\n",
            "19/19 [==============================] - 16s 838ms/step - loss: 1.1500 - accuracy: 0.6970 - val_loss: 1.5471 - val_accuracy: 0.5694\n",
            "Epoch 38/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 1.2238 - accuracy: 0.6806 - val_loss: 2.1961 - val_accuracy: 0.3958\n",
            "Epoch 39/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 1.2365 - accuracy: 0.6901 - val_loss: 1.7369 - val_accuracy: 0.5139\n",
            "Epoch 40/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 1.1638 - accuracy: 0.6892 - val_loss: 1.6863 - val_accuracy: 0.5486\n",
            "Epoch 41/98\n",
            "19/19 [==============================] - 15s 802ms/step - loss: 1.1165 - accuracy: 0.7066 - val_loss: 1.8538 - val_accuracy: 0.4722\n",
            "Epoch 42/98\n",
            "19/19 [==============================] - 16s 837ms/step - loss: 1.0974 - accuracy: 0.7144 - val_loss: 1.7220 - val_accuracy: 0.5139\n",
            "Epoch 43/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.1526 - accuracy: 0.7014 - val_loss: 3.3688 - val_accuracy: 0.2778\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 1.5678 - accuracy: 0.5208\n",
            "Test loss of the model is -  1.5678277015686035\n",
            "Test accuracy of the model is -  52.08333134651184 %\n",
            "Iteration:   0 | best local fitness (cost): 65.2777791\n",
            "EPOCHS:  97\n",
            "BATCH_SIZE:  50\n",
            "LEARNING_RATE:  0.003911635292154655\n",
            "Epoch 1/97\n",
            "24/24 [==============================] - 24s 704ms/step - loss: 40.0440 - accuracy: 0.2023 - val_loss: 3.6621 - val_accuracy: 0.1389\n",
            "Epoch 2/97\n",
            "24/24 [==============================] - 15s 637ms/step - loss: 2.5436 - accuracy: 0.2500 - val_loss: 2.5253 - val_accuracy: 0.3264\n",
            "Epoch 3/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 2.2387 - accuracy: 0.3012 - val_loss: 2.2324 - val_accuracy: 0.2153\n",
            "Epoch 4/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 2.0442 - accuracy: 0.3307 - val_loss: 2.1505 - val_accuracy: 0.2847\n",
            "Epoch 5/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 4.0374 - accuracy: 0.3064 - val_loss: 2.0185 - val_accuracy: 0.3889\n",
            "Epoch 6/97\n",
            "24/24 [==============================] - 15s 628ms/step - loss: 2.5121 - accuracy: 0.3333 - val_loss: 2.4774 - val_accuracy: 0.3194\n",
            "Epoch 7/97\n",
            "24/24 [==============================] - 15s 627ms/step - loss: 1.9618 - accuracy: 0.3672 - val_loss: 2.1991 - val_accuracy: 0.1875\n",
            "Epoch 8/97\n",
            "24/24 [==============================] - 15s 630ms/step - loss: 1.8517 - accuracy: 0.3785 - val_loss: 1.9487 - val_accuracy: 0.3264\n",
            "Epoch 9/97\n",
            "24/24 [==============================] - 15s 628ms/step - loss: 1.7641 - accuracy: 0.4132 - val_loss: 1.9049 - val_accuracy: 0.3889\n",
            "Epoch 10/97\n",
            "24/24 [==============================] - 15s 627ms/step - loss: 1.7726 - accuracy: 0.4245 - val_loss: 1.8572 - val_accuracy: 0.3958\n",
            "Epoch 11/97\n",
            "24/24 [==============================] - 15s 626ms/step - loss: 1.7524 - accuracy: 0.4488 - val_loss: 1.9137 - val_accuracy: 0.3542\n",
            "Epoch 12/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.7326 - accuracy: 0.4384 - val_loss: 2.0411 - val_accuracy: 0.3958\n",
            "Epoch 13/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.8324 - accuracy: 0.4271 - val_loss: 1.9472 - val_accuracy: 0.4375\n",
            "Epoch 14/97\n",
            "24/24 [==============================] - 15s 630ms/step - loss: 1.7966 - accuracy: 0.4470 - val_loss: 1.9219 - val_accuracy: 0.4306\n",
            "Epoch 15/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.8646 - accuracy: 0.4314 - val_loss: 2.0581 - val_accuracy: 0.4097\n",
            "Epoch 16/97\n",
            "24/24 [==============================] - 15s 630ms/step - loss: 1.7987 - accuracy: 0.4488 - val_loss: 1.8873 - val_accuracy: 0.3750\n",
            "Epoch 17/97\n",
            "24/24 [==============================] - 15s 631ms/step - loss: 1.7539 - accuracy: 0.4618 - val_loss: 1.9503 - val_accuracy: 0.3750\n",
            "Epoch 18/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.7824 - accuracy: 0.4479 - val_loss: 2.0173 - val_accuracy: 0.3264\n",
            "Epoch 19/97\n",
            "24/24 [==============================] - 15s 626ms/step - loss: 1.8041 - accuracy: 0.4688 - val_loss: 2.0514 - val_accuracy: 0.3542\n",
            "Epoch 20/97\n",
            "24/24 [==============================] - 15s 630ms/step - loss: 1.7625 - accuracy: 0.4766 - val_loss: 2.2124 - val_accuracy: 0.3958\n",
            "Epoch 21/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.7296 - accuracy: 0.4800 - val_loss: 2.2162 - val_accuracy: 0.2292\n",
            "Epoch 22/97\n",
            "24/24 [==============================] - 15s 631ms/step - loss: 1.7930 - accuracy: 0.4922 - val_loss: 2.0039 - val_accuracy: 0.4653\n",
            "Epoch 23/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.6646 - accuracy: 0.5035 - val_loss: 1.9189 - val_accuracy: 0.4861\n",
            "Epoch 24/97\n",
            "24/24 [==============================] - 15s 628ms/step - loss: 1.6821 - accuracy: 0.5139 - val_loss: 1.9450 - val_accuracy: 0.4236\n",
            "Epoch 25/97\n",
            "24/24 [==============================] - 15s 629ms/step - loss: 1.9813 - accuracy: 0.4297 - val_loss: 2.5003 - val_accuracy: 0.2083\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 1.8970 - accuracy: 0.3958\n",
            "Test loss of the model is -  1.8970082998275757\n",
            "Test accuracy of the model is -  39.58333432674408 %\n",
            "EPOCHS:  87\n",
            "BATCH_SIZE:  36\n",
            "LEARNING_RATE:  0.004183665066564939\n",
            "Epoch 1/87\n",
            "32/32 [==============================] - 22s 507ms/step - loss: 30.8326 - accuracy: 0.1988 - val_loss: 2.8623 - val_accuracy: 0.2569\n",
            "Epoch 2/87\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 2.3080 - accuracy: 0.2986 - val_loss: 2.3097 - val_accuracy: 0.2708\n",
            "Epoch 3/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.9942 - accuracy: 0.3368 - val_loss: 1.9267 - val_accuracy: 0.4167\n",
            "Epoch 4/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.9083 - accuracy: 0.3724 - val_loss: 1.7644 - val_accuracy: 0.4653\n",
            "Epoch 5/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.8470 - accuracy: 0.3889 - val_loss: 2.0568 - val_accuracy: 0.4097\n",
            "Epoch 6/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.8445 - accuracy: 0.4280 - val_loss: 1.9951 - val_accuracy: 0.3611\n",
            "Epoch 7/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7439 - accuracy: 0.4323 - val_loss: 1.8326 - val_accuracy: 0.4514\n",
            "Epoch 8/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7736 - accuracy: 0.4306 - val_loss: 1.8100 - val_accuracy: 0.4514\n",
            "Epoch 9/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7932 - accuracy: 0.4271 - val_loss: 1.9657 - val_accuracy: 0.3125\n",
            "Epoch 10/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.6948 - accuracy: 0.4644 - val_loss: 1.7885 - val_accuracy: 0.4097\n",
            "Epoch 11/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7613 - accuracy: 0.4444 - val_loss: 1.9025 - val_accuracy: 0.4583\n",
            "Epoch 12/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6947 - accuracy: 0.4661 - val_loss: 1.8259 - val_accuracy: 0.4097\n",
            "Epoch 13/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6417 - accuracy: 0.4696 - val_loss: 2.1194 - val_accuracy: 0.2917\n",
            "Epoch 14/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6102 - accuracy: 0.5000 - val_loss: 1.7715 - val_accuracy: 0.4375\n",
            "Epoch 15/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5809 - accuracy: 0.5165 - val_loss: 2.4707 - val_accuracy: 0.2569\n",
            "Epoch 16/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7227 - accuracy: 0.4905 - val_loss: 1.7685 - val_accuracy: 0.5000\n",
            "Epoch 17/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6679 - accuracy: 0.5122 - val_loss: 1.8014 - val_accuracy: 0.5069\n",
            "Epoch 18/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5989 - accuracy: 0.5286 - val_loss: 1.8255 - val_accuracy: 0.4167\n",
            "Epoch 19/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.5653 - accuracy: 0.5312 - val_loss: 1.8605 - val_accuracy: 0.4722\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.9096 - accuracy: 0.2986\n",
            "Test loss of the model is -  1.9096112251281738\n",
            "Test accuracy of the model is -  29.86111044883728 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  51\n",
            "LEARNING_RATE:  0.0016647160917598715\n",
            "Epoch 1/85\n",
            "23/23 [==============================] - 24s 681ms/step - loss: 10.8380 - accuracy: 0.2127 - val_loss: 2.7028 - val_accuracy: 0.1597\n",
            "Epoch 2/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 2.4051 - accuracy: 0.3021 - val_loss: 2.3177 - val_accuracy: 0.3125\n",
            "Epoch 3/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 2.0813 - accuracy: 0.3446 - val_loss: 2.1615 - val_accuracy: 0.3333\n",
            "Epoch 4/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.9199 - accuracy: 0.4019 - val_loss: 2.0104 - val_accuracy: 0.3611\n",
            "Epoch 5/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.8332 - accuracy: 0.4062 - val_loss: 2.0571 - val_accuracy: 0.2153\n",
            "Epoch 6/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.7068 - accuracy: 0.4609 - val_loss: 1.9746 - val_accuracy: 0.3958\n",
            "Epoch 7/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.6159 - accuracy: 0.4540 - val_loss: 1.8030 - val_accuracy: 0.3889\n",
            "Epoch 8/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.5420 - accuracy: 0.5009 - val_loss: 1.8614 - val_accuracy: 0.3750\n",
            "Epoch 9/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.4377 - accuracy: 0.5425 - val_loss: 1.6872 - val_accuracy: 0.4792\n",
            "Epoch 10/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.3429 - accuracy: 0.5851 - val_loss: 1.8047 - val_accuracy: 0.4028\n",
            "Epoch 11/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.3233 - accuracy: 0.6016 - val_loss: 1.5866 - val_accuracy: 0.6042\n",
            "Epoch 12/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.2595 - accuracy: 0.6233 - val_loss: 1.9195 - val_accuracy: 0.3681\n",
            "Epoch 13/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.2945 - accuracy: 0.5972 - val_loss: 1.7539 - val_accuracy: 0.4722\n",
            "Epoch 14/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.3048 - accuracy: 0.6076 - val_loss: 1.6568 - val_accuracy: 0.5139\n",
            "Epoch 15/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.1756 - accuracy: 0.6641 - val_loss: 1.6620 - val_accuracy: 0.4653\n",
            "Epoch 16/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 1.2671 - accuracy: 0.6580 - val_loss: 1.7487 - val_accuracy: 0.4375\n",
            "Epoch 17/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 1.1178 - accuracy: 0.6780 - val_loss: 1.6768 - val_accuracy: 0.4653\n",
            "Epoch 18/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 1.2061 - accuracy: 0.6632 - val_loss: 1.4740 - val_accuracy: 0.5556\n",
            "Epoch 19/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 1.1059 - accuracy: 0.6840 - val_loss: 1.5073 - val_accuracy: 0.5556\n",
            "Epoch 20/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.9577 - accuracy: 0.7604 - val_loss: 1.5253 - val_accuracy: 0.5486\n",
            "Epoch 21/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.9549 - accuracy: 0.7604 - val_loss: 1.4427 - val_accuracy: 0.5764\n",
            "Epoch 22/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.9684 - accuracy: 0.7422 - val_loss: 1.6004 - val_accuracy: 0.4722\n",
            "Epoch 23/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.9893 - accuracy: 0.7326 - val_loss: 1.3706 - val_accuracy: 0.6111\n",
            "Epoch 24/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.9373 - accuracy: 0.7778 - val_loss: 1.4028 - val_accuracy: 0.6250\n",
            "Epoch 25/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8923 - accuracy: 0.7778 - val_loss: 1.3839 - val_accuracy: 0.6250\n",
            "Epoch 26/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.8817 - accuracy: 0.7951 - val_loss: 1.3228 - val_accuracy: 0.6111\n",
            "Epoch 27/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8976 - accuracy: 0.7604 - val_loss: 1.5029 - val_accuracy: 0.5764\n",
            "Epoch 28/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.9330 - accuracy: 0.7769 - val_loss: 1.5867 - val_accuracy: 0.5556\n",
            "Epoch 29/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8951 - accuracy: 0.7778 - val_loss: 1.4017 - val_accuracy: 0.6528\n",
            "Epoch 30/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8535 - accuracy: 0.7882 - val_loss: 1.3616 - val_accuracy: 0.6319\n",
            "Epoch 31/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.8244 - accuracy: 0.8090 - val_loss: 2.0412 - val_accuracy: 0.4375\n",
            "Epoch 32/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8021 - accuracy: 0.8151 - val_loss: 1.4456 - val_accuracy: 0.5903\n",
            "Epoch 33/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 0.7602 - accuracy: 0.8255 - val_loss: 1.4992 - val_accuracy: 0.5556\n",
            "Epoch 34/85\n",
            "23/23 [==============================] - 15s 651ms/step - loss: 0.8315 - accuracy: 0.8073 - val_loss: 1.3953 - val_accuracy: 0.6250\n",
            "Epoch 35/85\n",
            "23/23 [==============================] - 15s 652ms/step - loss: 0.8029 - accuracy: 0.8186 - val_loss: 1.4258 - val_accuracy: 0.6319\n",
            "Epoch 36/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.8276 - accuracy: 0.8255 - val_loss: 1.4633 - val_accuracy: 0.6597\n",
            "Epoch 37/85\n",
            "23/23 [==============================] - 15s 653ms/step - loss: 0.7700 - accuracy: 0.8368 - val_loss: 1.5430 - val_accuracy: 0.5903\n",
            "Epoch 38/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.7536 - accuracy: 0.8359 - val_loss: 1.4895 - val_accuracy: 0.5903\n",
            "Epoch 39/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.7665 - accuracy: 0.8307 - val_loss: 1.5856 - val_accuracy: 0.5764\n",
            "Epoch 40/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.7170 - accuracy: 0.8576 - val_loss: 1.4664 - val_accuracy: 0.6389\n",
            "Epoch 41/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.6776 - accuracy: 0.8655 - val_loss: 1.3953 - val_accuracy: 0.6111\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 1.3451 - accuracy: 0.6458\n",
            "Test loss of the model is -  1.3451275825500488\n",
            "Test accuracy of the model is -  64.58333134651184 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  39\n",
            "LEARNING_RATE:  0.0018798223125886461\n",
            "Epoch 1/85\n",
            "30/30 [==============================] - 21s 506ms/step - loss: 5.3385 - accuracy: 0.2214 - val_loss: 2.5769 - val_accuracy: 0.3472\n",
            "Epoch 2/85\n",
            "30/30 [==============================] - 15s 494ms/step - loss: 2.2081 - accuracy: 0.3290 - val_loss: 2.2666 - val_accuracy: 0.2917\n",
            "Epoch 3/85\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 1.9470 - accuracy: 0.3898 - val_loss: 2.0400 - val_accuracy: 0.2847\n",
            "Epoch 4/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.7893 - accuracy: 0.4002 - val_loss: 1.8692 - val_accuracy: 0.4306\n",
            "Epoch 5/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.7090 - accuracy: 0.4375 - val_loss: 1.8908 - val_accuracy: 0.3958\n",
            "Epoch 6/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.5804 - accuracy: 0.4957 - val_loss: 1.7759 - val_accuracy: 0.4514\n",
            "Epoch 7/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.5507 - accuracy: 0.4974 - val_loss: 1.7402 - val_accuracy: 0.4792\n",
            "Epoch 8/85\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.5345 - accuracy: 0.4939 - val_loss: 1.6819 - val_accuracy: 0.4931\n",
            "Epoch 9/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.4780 - accuracy: 0.5200 - val_loss: 1.6212 - val_accuracy: 0.5347\n",
            "Epoch 10/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.4191 - accuracy: 0.5634 - val_loss: 1.7561 - val_accuracy: 0.4375\n",
            "Epoch 11/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.3946 - accuracy: 0.5547 - val_loss: 1.5296 - val_accuracy: 0.6042\n",
            "Epoch 12/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.3334 - accuracy: 0.6076 - val_loss: 1.5417 - val_accuracy: 0.5347\n",
            "Epoch 13/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.3133 - accuracy: 0.5998 - val_loss: 1.6662 - val_accuracy: 0.4722\n",
            "Epoch 14/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.2693 - accuracy: 0.6111 - val_loss: 1.5245 - val_accuracy: 0.5417\n",
            "Epoch 15/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.1992 - accuracy: 0.6562 - val_loss: 1.5150 - val_accuracy: 0.5556\n",
            "Epoch 16/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.1922 - accuracy: 0.6345 - val_loss: 1.6910 - val_accuracy: 0.4306\n",
            "Epoch 17/85\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 1.1828 - accuracy: 0.6536 - val_loss: 1.4633 - val_accuracy: 0.5903\n",
            "Epoch 18/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.1658 - accuracy: 0.6597 - val_loss: 1.5936 - val_accuracy: 0.5208\n",
            "Epoch 19/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.1568 - accuracy: 0.6658 - val_loss: 1.4827 - val_accuracy: 0.5625\n",
            "Epoch 20/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.1980 - accuracy: 0.6536 - val_loss: 1.5732 - val_accuracy: 0.5694\n",
            "Epoch 21/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.0893 - accuracy: 0.7083 - val_loss: 1.4066 - val_accuracy: 0.5556\n",
            "Epoch 22/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0082 - accuracy: 0.7344 - val_loss: 1.5837 - val_accuracy: 0.6111\n",
            "Epoch 23/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.0112 - accuracy: 0.7292 - val_loss: 1.3583 - val_accuracy: 0.6181\n",
            "Epoch 24/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.0051 - accuracy: 0.7292 - val_loss: 1.4377 - val_accuracy: 0.6389\n",
            "Epoch 25/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0462 - accuracy: 0.7170 - val_loss: 1.2406 - val_accuracy: 0.6736\n",
            "Epoch 26/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.9411 - accuracy: 0.7639 - val_loss: 1.4906 - val_accuracy: 0.6319\n",
            "Epoch 27/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.9666 - accuracy: 0.7561 - val_loss: 1.2616 - val_accuracy: 0.6597\n",
            "Epoch 28/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.0115 - accuracy: 0.7483 - val_loss: 1.2812 - val_accuracy: 0.6458\n",
            "Epoch 29/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.9904 - accuracy: 0.7517 - val_loss: 1.5819 - val_accuracy: 0.5486\n",
            "Epoch 30/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.9261 - accuracy: 0.7630 - val_loss: 1.3936 - val_accuracy: 0.5764\n",
            "Epoch 31/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.9343 - accuracy: 0.7674 - val_loss: 1.2649 - val_accuracy: 0.6458\n",
            "Epoch 32/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.9146 - accuracy: 0.7847 - val_loss: 1.3472 - val_accuracy: 0.6181\n",
            "Epoch 33/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.9640 - accuracy: 0.7543 - val_loss: 1.5925 - val_accuracy: 0.5694\n",
            "Epoch 34/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.8594 - accuracy: 0.7951 - val_loss: 1.3698 - val_accuracy: 0.6181\n",
            "Epoch 35/85\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 0.8589 - accuracy: 0.7969 - val_loss: 1.2740 - val_accuracy: 0.6597\n",
            "Epoch 36/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.8358 - accuracy: 0.8082 - val_loss: 1.3650 - val_accuracy: 0.6319\n",
            "Epoch 37/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.7880 - accuracy: 0.8125 - val_loss: 1.3123 - val_accuracy: 0.6319\n",
            "Epoch 38/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.8435 - accuracy: 0.7847 - val_loss: 1.3742 - val_accuracy: 0.6528\n",
            "Epoch 39/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.7958 - accuracy: 0.8220 - val_loss: 1.3052 - val_accuracy: 0.6458\n",
            "Epoch 40/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.8174 - accuracy: 0.8168 - val_loss: 1.7461 - val_accuracy: 0.5486\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.4565 - accuracy: 0.6389\n",
            "Test loss of the model is -  1.456475853919983\n",
            "Test accuracy of the model is -  63.88888955116272 %\n",
            "EPOCHS:  98\n",
            "BATCH_SIZE:  62\n",
            "LEARNING_RATE:  0.0032872209120587683\n",
            "Epoch 1/98\n",
            "19/19 [==============================] - 23s 881ms/step - loss: 32.0735 - accuracy: 0.2153 - val_loss: 2.7509 - val_accuracy: 0.3264\n",
            "Epoch 2/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 2.3576 - accuracy: 0.3168 - val_loss: 2.2442 - val_accuracy: 0.3611\n",
            "Epoch 3/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 2.1017 - accuracy: 0.3516 - val_loss: 2.2319 - val_accuracy: 0.3472\n",
            "Epoch 4/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.9160 - accuracy: 0.3845 - val_loss: 1.9724 - val_accuracy: 0.3958\n",
            "Epoch 5/98\n",
            "19/19 [==============================] - 15s 803ms/step - loss: 1.8319 - accuracy: 0.4132 - val_loss: 2.1047 - val_accuracy: 0.3750\n",
            "Epoch 6/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.7838 - accuracy: 0.4149 - val_loss: 1.9220 - val_accuracy: 0.3819\n",
            "Epoch 7/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.7210 - accuracy: 0.4184 - val_loss: 1.9619 - val_accuracy: 0.3611\n",
            "Epoch 8/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.6798 - accuracy: 0.4479 - val_loss: 1.9026 - val_accuracy: 0.3403\n",
            "Epoch 9/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.5839 - accuracy: 0.4592 - val_loss: 1.8047 - val_accuracy: 0.3958\n",
            "Epoch 10/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.5222 - accuracy: 0.4991 - val_loss: 1.7646 - val_accuracy: 0.4236\n",
            "Epoch 11/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.5168 - accuracy: 0.5113 - val_loss: 1.7863 - val_accuracy: 0.4653\n",
            "Epoch 12/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 1.5134 - accuracy: 0.5174 - val_loss: 1.8014 - val_accuracy: 0.3542\n",
            "Epoch 13/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.5137 - accuracy: 0.5200 - val_loss: 1.7347 - val_accuracy: 0.4306\n",
            "Epoch 14/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.4640 - accuracy: 0.5365 - val_loss: 1.8112 - val_accuracy: 0.3750\n",
            "Epoch 15/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4142 - accuracy: 0.5495 - val_loss: 1.6660 - val_accuracy: 0.4722\n",
            "Epoch 16/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4027 - accuracy: 0.5816 - val_loss: 1.7312 - val_accuracy: 0.4861\n",
            "Epoch 17/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4472 - accuracy: 0.5694 - val_loss: 1.7912 - val_accuracy: 0.4028\n",
            "Epoch 18/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.3972 - accuracy: 0.5894 - val_loss: 1.9813 - val_accuracy: 0.3819\n",
            "Epoch 19/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.3114 - accuracy: 0.6363 - val_loss: 1.7228 - val_accuracy: 0.4444\n",
            "Epoch 20/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.3769 - accuracy: 0.5981 - val_loss: 1.7096 - val_accuracy: 0.4722\n",
            "Epoch 21/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.4410 - accuracy: 0.5868 - val_loss: 1.7863 - val_accuracy: 0.4861\n",
            "Epoch 22/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.4613 - accuracy: 0.5964 - val_loss: 1.7407 - val_accuracy: 0.5417\n",
            "Epoch 23/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 1.3527 - accuracy: 0.6380 - val_loss: 1.5975 - val_accuracy: 0.5486\n",
            "Epoch 24/98\n",
            "19/19 [==============================] - 15s 804ms/step - loss: 1.2330 - accuracy: 0.6415 - val_loss: 1.8730 - val_accuracy: 0.4722\n",
            "Epoch 25/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.1848 - accuracy: 0.6762 - val_loss: 1.6229 - val_accuracy: 0.5625\n",
            "Epoch 26/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.1437 - accuracy: 0.6727 - val_loss: 1.9026 - val_accuracy: 0.4444\n",
            "Epoch 27/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.1274 - accuracy: 0.7170 - val_loss: 1.5150 - val_accuracy: 0.5972\n",
            "Epoch 28/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.1413 - accuracy: 0.6979 - val_loss: 1.5643 - val_accuracy: 0.5694\n",
            "Epoch 29/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.2095 - accuracy: 0.6753 - val_loss: 1.5241 - val_accuracy: 0.5903\n",
            "Epoch 30/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.1696 - accuracy: 0.6866 - val_loss: 1.6672 - val_accuracy: 0.6042\n",
            "Epoch 31/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.2263 - accuracy: 0.6684 - val_loss: 1.6267 - val_accuracy: 0.5069\n",
            "Epoch 32/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.1725 - accuracy: 0.7005 - val_loss: 1.5584 - val_accuracy: 0.5417\n",
            "Epoch 33/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.1598 - accuracy: 0.7179 - val_loss: 1.4320 - val_accuracy: 0.6250\n",
            "Epoch 34/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0953 - accuracy: 0.7214 - val_loss: 1.3995 - val_accuracy: 0.6111\n",
            "Epoch 35/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.0849 - accuracy: 0.7292 - val_loss: 1.6368 - val_accuracy: 0.5347\n",
            "Epoch 36/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0365 - accuracy: 0.7387 - val_loss: 1.7095 - val_accuracy: 0.6042\n",
            "Epoch 37/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.0728 - accuracy: 0.7431 - val_loss: 1.6070 - val_accuracy: 0.5556\n",
            "Epoch 38/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0462 - accuracy: 0.7465 - val_loss: 1.7496 - val_accuracy: 0.4653\n",
            "Epoch 39/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.0384 - accuracy: 0.7413 - val_loss: 1.6980 - val_accuracy: 0.5972\n",
            "Epoch 40/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0501 - accuracy: 0.7561 - val_loss: 1.4747 - val_accuracy: 0.7014\n",
            "Epoch 41/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.1008 - accuracy: 0.7448 - val_loss: 1.7792 - val_accuracy: 0.5000\n",
            "Epoch 42/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 1.0583 - accuracy: 0.7517 - val_loss: 1.4443 - val_accuracy: 0.5972\n",
            "Epoch 43/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.0069 - accuracy: 0.7639 - val_loss: 1.6429 - val_accuracy: 0.5486\n",
            "Epoch 44/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.0027 - accuracy: 0.7778 - val_loss: 1.4134 - val_accuracy: 0.6181\n",
            "Epoch 45/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 113.4798 - accuracy: 0.6311 - val_loss: 5.8820 - val_accuracy: 0.2153\n",
            "Epoch 46/98\n",
            "19/19 [==============================] - 15s 805ms/step - loss: 5.4944 - accuracy: 0.4523 - val_loss: 3.0529 - val_accuracy: 0.3750\n",
            "Epoch 47/98\n",
            "19/19 [==============================] - 16s 839ms/step - loss: 134.8211 - accuracy: 0.3377 - val_loss: 5.3389 - val_accuracy: 0.1806\n",
            "Epoch 48/98\n",
            "19/19 [==============================] - 16s 837ms/step - loss: 693.1406 - accuracy: 0.2135 - val_loss: 6.3397 - val_accuracy: 0.1736\n",
            "Epoch 49/98\n",
            "19/19 [==============================] - 15s 801ms/step - loss: 8.5146 - accuracy: 0.2005 - val_loss: 2.9813 - val_accuracy: 0.1528\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.5988 - accuracy: 0.5694\n",
            "Test loss of the model is -  1.5988197326660156\n",
            "Test accuracy of the model is -  56.94444179534912 %\n",
            "EPOCHS:  97\n",
            "BATCH_SIZE:  50\n",
            "LEARNING_RATE:  0.003911635292154655\n",
            "Epoch 1/97\n",
            "24/24 [==============================] - 21s 655ms/step - loss: 150.1768 - accuracy: 0.1918 - val_loss: 8.2106 - val_accuracy: 0.2153\n",
            "Epoch 2/97\n",
            "24/24 [==============================] - 15s 639ms/step - loss: 3.7989 - accuracy: 0.2509 - val_loss: 2.2477 - val_accuracy: 0.3125\n",
            "Epoch 3/97\n",
            "24/24 [==============================] - 15s 639ms/step - loss: 2.1649 - accuracy: 0.2943 - val_loss: 1.9903 - val_accuracy: 0.3472\n",
            "Epoch 4/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.9581 - accuracy: 0.3637 - val_loss: 2.1905 - val_accuracy: 0.2917\n",
            "Epoch 5/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 2.0065 - accuracy: 0.3220 - val_loss: 2.1449 - val_accuracy: 0.3056\n",
            "Epoch 6/97\n",
            "24/24 [==============================] - 15s 631ms/step - loss: 1.8914 - accuracy: 0.3785 - val_loss: 2.1924 - val_accuracy: 0.2153\n",
            "Epoch 7/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.8870 - accuracy: 0.3958 - val_loss: 2.0181 - val_accuracy: 0.3264\n",
            "Epoch 8/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.7612 - accuracy: 0.4071 - val_loss: 1.8537 - val_accuracy: 0.4167\n",
            "Epoch 9/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.7664 - accuracy: 0.4167 - val_loss: 1.8753 - val_accuracy: 0.3889\n",
            "Epoch 10/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.8598 - accuracy: 0.3984 - val_loss: 2.1227 - val_accuracy: 0.3194\n",
            "Epoch 11/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7805 - accuracy: 0.4479 - val_loss: 1.9166 - val_accuracy: 0.3194\n",
            "Epoch 12/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.7840 - accuracy: 0.4193 - val_loss: 1.9225 - val_accuracy: 0.3750\n",
            "Epoch 13/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.7555 - accuracy: 0.4462 - val_loss: 1.9367 - val_accuracy: 0.3333\n",
            "Epoch 14/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.7621 - accuracy: 0.4462 - val_loss: 1.9126 - val_accuracy: 0.3611\n",
            "Epoch 15/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7465 - accuracy: 0.4514 - val_loss: 2.0573 - val_accuracy: 0.2292\n",
            "Epoch 16/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.6843 - accuracy: 0.4705 - val_loss: 1.8616 - val_accuracy: 0.3889\n",
            "Epoch 17/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.7649 - accuracy: 0.4644 - val_loss: 2.1509 - val_accuracy: 0.3542\n",
            "Epoch 18/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.7707 - accuracy: 0.4670 - val_loss: 1.8657 - val_accuracy: 0.3889\n",
            "Epoch 19/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7463 - accuracy: 0.4714 - val_loss: 2.0335 - val_accuracy: 0.3125\n",
            "Epoch 20/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.8087 - accuracy: 0.4384 - val_loss: 2.0665 - val_accuracy: 0.3542\n",
            "Epoch 21/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.7110 - accuracy: 0.4661 - val_loss: 2.0116 - val_accuracy: 0.3542\n",
            "Epoch 22/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.7978 - accuracy: 0.4523 - val_loss: 2.3722 - val_accuracy: 0.2639\n",
            "Epoch 23/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.8279 - accuracy: 0.4523 - val_loss: 1.9477 - val_accuracy: 0.4583\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 2.0048 - accuracy: 0.2847\n",
            "Test loss of the model is -  2.0047924518585205\n",
            "Test accuracy of the model is -  28.47222089767456 %\n",
            "EPOCHS:  87\n",
            "BATCH_SIZE:  36\n",
            "LEARNING_RATE:  0.004183665066564939\n",
            "Epoch 1/87\n",
            "32/32 [==============================] - 22s 479ms/step - loss: 59.0903 - accuracy: 0.2109 - val_loss: 3.3271 - val_accuracy: 0.2431\n",
            "Epoch 2/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 2.3806 - accuracy: 0.3021 - val_loss: 2.1941 - val_accuracy: 0.3681\n",
            "Epoch 3/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 2.0097 - accuracy: 0.3594 - val_loss: 2.4671 - val_accuracy: 0.2361\n",
            "Epoch 4/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.9638 - accuracy: 0.3559 - val_loss: 1.8989 - val_accuracy: 0.4375\n",
            "Epoch 5/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7937 - accuracy: 0.4227 - val_loss: 2.0173 - val_accuracy: 0.3194\n",
            "Epoch 6/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7747 - accuracy: 0.4167 - val_loss: 1.9162 - val_accuracy: 0.3472\n",
            "Epoch 7/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.8004 - accuracy: 0.4384 - val_loss: 2.1911 - val_accuracy: 0.2361\n",
            "Epoch 8/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7562 - accuracy: 0.4436 - val_loss: 1.8007 - val_accuracy: 0.4444\n",
            "Epoch 9/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.7086 - accuracy: 0.4609 - val_loss: 2.0536 - val_accuracy: 0.2986\n",
            "Epoch 10/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.7598 - accuracy: 0.4583 - val_loss: 2.0265 - val_accuracy: 0.2986\n",
            "Epoch 11/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6415 - accuracy: 0.4852 - val_loss: 1.7631 - val_accuracy: 0.4583\n",
            "Epoch 12/87\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.5703 - accuracy: 0.5208 - val_loss: 1.7836 - val_accuracy: 0.4167\n",
            "Epoch 13/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5971 - accuracy: 0.5148 - val_loss: 2.0384 - val_accuracy: 0.2569\n",
            "Epoch 14/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5667 - accuracy: 0.5113 - val_loss: 1.7969 - val_accuracy: 0.4306\n",
            "Epoch 15/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6611 - accuracy: 0.5095 - val_loss: 1.7667 - val_accuracy: 0.5139\n",
            "Epoch 16/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.6300 - accuracy: 0.5156 - val_loss: 1.7961 - val_accuracy: 0.4375\n",
            "Epoch 17/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.5462 - accuracy: 0.5451 - val_loss: 1.6890 - val_accuracy: 0.4583\n",
            "Epoch 18/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.4921 - accuracy: 0.5729 - val_loss: 2.2082 - val_accuracy: 0.3542\n",
            "Epoch 19/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.5387 - accuracy: 0.5451 - val_loss: 1.9301 - val_accuracy: 0.4583\n",
            "Epoch 20/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5085 - accuracy: 0.5694 - val_loss: 1.7126 - val_accuracy: 0.5208\n",
            "Epoch 21/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5423 - accuracy: 0.5703 - val_loss: 1.8203 - val_accuracy: 0.4931\n",
            "Epoch 22/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.4815 - accuracy: 0.5816 - val_loss: 1.7384 - val_accuracy: 0.4514\n",
            "Epoch 23/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.4270 - accuracy: 0.5825 - val_loss: 1.7823 - val_accuracy: 0.5139\n",
            "Epoch 24/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5748 - accuracy: 0.5651 - val_loss: 1.8338 - val_accuracy: 0.5347\n",
            "Epoch 25/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.5129 - accuracy: 0.5894 - val_loss: 1.8210 - val_accuracy: 0.4792\n",
            "Epoch 26/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.4490 - accuracy: 0.6146 - val_loss: 1.8262 - val_accuracy: 0.4861\n",
            "Epoch 27/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.4691 - accuracy: 0.6094 - val_loss: 1.7739 - val_accuracy: 0.5208\n",
            "Epoch 28/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.3878 - accuracy: 0.6293 - val_loss: 1.6527 - val_accuracy: 0.5556\n",
            "Epoch 29/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.3600 - accuracy: 0.6311 - val_loss: 1.6035 - val_accuracy: 0.5764\n",
            "Epoch 30/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.5136 - accuracy: 0.5955 - val_loss: 1.7214 - val_accuracy: 0.5556\n",
            "Epoch 31/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.4411 - accuracy: 0.6224 - val_loss: 2.0409 - val_accuracy: 0.4028\n",
            "Epoch 32/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.3785 - accuracy: 0.6354 - val_loss: 1.5035 - val_accuracy: 0.5972\n",
            "Epoch 33/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.3150 - accuracy: 0.6415 - val_loss: 1.6226 - val_accuracy: 0.5903\n",
            "Epoch 34/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.2762 - accuracy: 0.6502 - val_loss: 1.6980 - val_accuracy: 0.5347\n",
            "Epoch 35/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.2516 - accuracy: 0.6745 - val_loss: 1.5857 - val_accuracy: 0.5694\n",
            "Epoch 36/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.2964 - accuracy: 0.6675 - val_loss: 1.8403 - val_accuracy: 0.5694\n",
            "Epoch 37/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.3317 - accuracy: 0.6641 - val_loss: 1.5946 - val_accuracy: 0.5833\n",
            "Epoch 38/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.4247 - accuracy: 0.6580 - val_loss: 1.9537 - val_accuracy: 0.5972\n",
            "Epoch 39/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5079 - accuracy: 0.6450 - val_loss: 1.8094 - val_accuracy: 0.5625\n",
            "Epoch 40/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.3514 - accuracy: 0.6736 - val_loss: 2.0375 - val_accuracy: 0.4097\n",
            "Epoch 41/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.3421 - accuracy: 0.6632 - val_loss: 1.6036 - val_accuracy: 0.5417\n",
            "Epoch 42/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.2101 - accuracy: 0.6736 - val_loss: 1.7331 - val_accuracy: 0.5139\n",
            "Epoch 43/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.1717 - accuracy: 0.6988 - val_loss: 1.6544 - val_accuracy: 0.5625\n",
            "Epoch 44/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.1747 - accuracy: 0.7057 - val_loss: 1.7359 - val_accuracy: 0.5903\n",
            "Epoch 45/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.3182 - accuracy: 0.6814 - val_loss: 1.5612 - val_accuracy: 0.5972\n",
            "Epoch 46/87\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.2915 - accuracy: 0.6849 - val_loss: 1.7727 - val_accuracy: 0.4792\n",
            "Epoch 47/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.1562 - accuracy: 0.7240 - val_loss: 1.6610 - val_accuracy: 0.5278\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 1.7971 - accuracy: 0.4653\n",
            "Test loss of the model is -  1.7971311807632446\n",
            "Test accuracy of the model is -  46.52777910232544 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  51\n",
            "LEARNING_RATE:  0.0016647160917598715\n",
            "Epoch 1/85\n",
            "23/23 [==============================] - 23s 679ms/step - loss: 7.6055 - accuracy: 0.2266 - val_loss: 2.6862 - val_accuracy: 0.3056\n",
            "Epoch 2/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 2.4085 - accuracy: 0.3108 - val_loss: 2.3563 - val_accuracy: 0.1667\n",
            "Epoch 3/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 1.8690 - accuracy: 0.4158 - val_loss: 2.0366 - val_accuracy: 0.3819\n",
            "Epoch 5/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.7478 - accuracy: 0.4575 - val_loss: 1.9632 - val_accuracy: 0.3403\n",
            "Epoch 6/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.6078 - accuracy: 0.5000 - val_loss: 1.9006 - val_accuracy: 0.3889\n",
            "Epoch 7/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.5289 - accuracy: 0.5226 - val_loss: 1.8767 - val_accuracy: 0.4236\n",
            "Epoch 8/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.4951 - accuracy: 0.5312 - val_loss: 1.8252 - val_accuracy: 0.4583\n",
            "Epoch 9/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.4099 - accuracy: 0.5790 - val_loss: 1.7436 - val_accuracy: 0.4236\n",
            "Epoch 10/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.3030 - accuracy: 0.5903 - val_loss: 1.6432 - val_accuracy: 0.5347\n",
            "Epoch 11/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.2396 - accuracy: 0.6337 - val_loss: 1.6653 - val_accuracy: 0.4375\n",
            "Epoch 12/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.2004 - accuracy: 0.6502 - val_loss: 1.6414 - val_accuracy: 0.4722\n",
            "Epoch 13/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 1.1385 - accuracy: 0.6719 - val_loss: 1.6574 - val_accuracy: 0.4861\n",
            "Epoch 14/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.1934 - accuracy: 0.6684 - val_loss: 1.4841 - val_accuracy: 0.5972\n",
            "Epoch 15/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 1.1760 - accuracy: 0.6510 - val_loss: 1.5100 - val_accuracy: 0.5833\n",
            "Epoch 16/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.1173 - accuracy: 0.6997 - val_loss: 1.5813 - val_accuracy: 0.5139\n",
            "Epoch 17/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 1.0543 - accuracy: 0.7092 - val_loss: 1.5906 - val_accuracy: 0.5139\n",
            "Epoch 18/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 1.0251 - accuracy: 0.7318 - val_loss: 1.4799 - val_accuracy: 0.5625\n",
            "Epoch 19/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.9817 - accuracy: 0.7465 - val_loss: 1.4858 - val_accuracy: 0.5972\n",
            "Epoch 20/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.9142 - accuracy: 0.7578 - val_loss: 1.3436 - val_accuracy: 0.6250\n",
            "Epoch 21/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.9377 - accuracy: 0.7448 - val_loss: 1.4396 - val_accuracy: 0.5833\n",
            "Epoch 22/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8863 - accuracy: 0.7908 - val_loss: 1.4292 - val_accuracy: 0.6389\n",
            "Epoch 23/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.8698 - accuracy: 0.7839 - val_loss: 1.3125 - val_accuracy: 0.6597\n",
            "Epoch 24/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.8759 - accuracy: 0.8003 - val_loss: 1.4639 - val_accuracy: 0.5417\n",
            "Epoch 25/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8541 - accuracy: 0.8021 - val_loss: 1.3266 - val_accuracy: 0.6458\n",
            "Epoch 26/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.8015 - accuracy: 0.8125 - val_loss: 1.9504 - val_accuracy: 0.3958\n",
            "Epoch 27/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.8346 - accuracy: 0.8021 - val_loss: 1.4481 - val_accuracy: 0.5903\n",
            "Epoch 28/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.8526 - accuracy: 0.8030 - val_loss: 1.4543 - val_accuracy: 0.5972\n",
            "Epoch 29/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.8412 - accuracy: 0.7908 - val_loss: 1.5725 - val_accuracy: 0.5486\n",
            "Epoch 30/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.7912 - accuracy: 0.8220 - val_loss: 1.3105 - val_accuracy: 0.6528\n",
            "Epoch 31/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.8134 - accuracy: 0.8116 - val_loss: 1.2574 - val_accuracy: 0.7222\n",
            "Epoch 32/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7571 - accuracy: 0.8420 - val_loss: 1.2612 - val_accuracy: 0.6736\n",
            "Epoch 33/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7288 - accuracy: 0.8411 - val_loss: 1.1898 - val_accuracy: 0.6806\n",
            "Epoch 34/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6846 - accuracy: 0.8568 - val_loss: 1.2477 - val_accuracy: 0.6875\n",
            "Epoch 35/85\n",
            "23/23 [==============================] - 15s 660ms/step - loss: 0.6938 - accuracy: 0.8533 - val_loss: 1.1799 - val_accuracy: 0.7292\n",
            "Epoch 36/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7336 - accuracy: 0.8333 - val_loss: 1.3387 - val_accuracy: 0.6944\n",
            "Epoch 37/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.7082 - accuracy: 0.8472 - val_loss: 1.2198 - val_accuracy: 0.6736\n",
            "Epoch 38/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.6601 - accuracy: 0.8681 - val_loss: 1.3592 - val_accuracy: 0.6319\n",
            "Epoch 39/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.7457 - accuracy: 0.8307 - val_loss: 1.3144 - val_accuracy: 0.6667\n",
            "Epoch 40/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.6990 - accuracy: 0.8611 - val_loss: 1.2706 - val_accuracy: 0.6111\n",
            "Epoch 41/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6684 - accuracy: 0.8550 - val_loss: 1.1682 - val_accuracy: 0.7153\n",
            "Epoch 42/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6838 - accuracy: 0.8559 - val_loss: 1.2145 - val_accuracy: 0.6667\n",
            "Epoch 43/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6518 - accuracy: 0.8672 - val_loss: 1.4195 - val_accuracy: 0.6458\n",
            "Epoch 44/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6421 - accuracy: 0.8759 - val_loss: 2.0715 - val_accuracy: 0.4861\n",
            "Epoch 45/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.6662 - accuracy: 0.8611 - val_loss: 1.2001 - val_accuracy: 0.6667\n",
            "Epoch 46/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6684 - accuracy: 0.8620 - val_loss: 1.2912 - val_accuracy: 0.6319\n",
            "Epoch 47/85\n",
            "23/23 [==============================] - 15s 659ms/step - loss: 0.6499 - accuracy: 0.8724 - val_loss: 1.1151 - val_accuracy: 0.7222\n",
            "Epoch 48/85\n",
            "23/23 [==============================] - 15s 654ms/step - loss: 0.6593 - accuracy: 0.8707 - val_loss: 1.4180 - val_accuracy: 0.5972\n",
            "Epoch 49/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6068 - accuracy: 0.8854 - val_loss: 1.1784 - val_accuracy: 0.6806\n",
            "Epoch 50/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.5353 - accuracy: 0.9184 - val_loss: 1.2118 - val_accuracy: 0.7083\n",
            "Epoch 51/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5238 - accuracy: 0.9080 - val_loss: 1.3600 - val_accuracy: 0.6319\n",
            "Epoch 52/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5525 - accuracy: 0.8924 - val_loss: 1.3156 - val_accuracy: 0.6597\n",
            "Epoch 53/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.5029 - accuracy: 0.9149 - val_loss: 1.3912 - val_accuracy: 0.6597\n",
            "Epoch 54/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6154 - accuracy: 0.8698 - val_loss: 1.4655 - val_accuracy: 0.6597\n",
            "Epoch 55/85\n",
            "23/23 [==============================] - 15s 655ms/step - loss: 0.6648 - accuracy: 0.8689 - val_loss: 1.5358 - val_accuracy: 0.6319\n",
            "Epoch 56/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.6604 - accuracy: 0.8750 - val_loss: 1.1191 - val_accuracy: 0.6875\n",
            "Epoch 57/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.5753 - accuracy: 0.8915 - val_loss: 1.2224 - val_accuracy: 0.6806\n",
            "Epoch 58/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5146 - accuracy: 0.9184 - val_loss: 1.2292 - val_accuracy: 0.6458\n",
            "Epoch 59/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.4971 - accuracy: 0.9097 - val_loss: 1.3216 - val_accuracy: 0.6181\n",
            "Epoch 60/85\n",
            "23/23 [==============================] - 15s 656ms/step - loss: 0.4942 - accuracy: 0.9158 - val_loss: 1.2448 - val_accuracy: 0.6597\n",
            "Epoch 61/85\n",
            "23/23 [==============================] - 15s 657ms/step - loss: 0.5044 - accuracy: 0.9097 - val_loss: 1.4196 - val_accuracy: 0.6667\n",
            "Epoch 62/85\n",
            "23/23 [==============================] - 15s 658ms/step - loss: 0.5042 - accuracy: 0.9149 - val_loss: 1.3491 - val_accuracy: 0.6736\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 1.3729 - accuracy: 0.6597\n",
            "Test loss of the model is -  1.3729348182678223\n",
            "Test accuracy of the model is -  65.97222089767456 %\n",
            "EPOCHS:  85\n",
            "BATCH_SIZE:  39\n",
            "LEARNING_RATE:  0.0018798223125886461\n",
            "Epoch 1/85\n",
            "30/30 [==============================] - 21s 505ms/step - loss: 15.7402 - accuracy: 0.1944 - val_loss: 2.4443 - val_accuracy: 0.3819\n",
            "Epoch 2/85\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 2.4140 - accuracy: 0.2873 - val_loss: 2.1449 - val_accuracy: 0.3958\n",
            "Epoch 3/85\n",
            "30/30 [==============================] - 15s 495ms/step - loss: 2.1151 - accuracy: 0.3368 - val_loss: 2.1040 - val_accuracy: 0.3264\n",
            "Epoch 4/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.8750 - accuracy: 0.4123 - val_loss: 2.2120 - val_accuracy: 0.1875\n",
            "Epoch 5/85\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 1.8145 - accuracy: 0.4141 - val_loss: 1.9127 - val_accuracy: 0.4444\n",
            "Epoch 6/85\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.7641 - accuracy: 0.4497 - val_loss: 1.8196 - val_accuracy: 0.4236\n",
            "Epoch 7/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.6627 - accuracy: 0.4757 - val_loss: 1.7110 - val_accuracy: 0.5069\n",
            "Epoch 8/85\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.5741 - accuracy: 0.4983 - val_loss: 1.6776 - val_accuracy: 0.5556\n",
            "Epoch 9/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.5224 - accuracy: 0.5304 - val_loss: 1.6894 - val_accuracy: 0.5208\n",
            "Epoch 10/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.4262 - accuracy: 0.5599 - val_loss: 1.7068 - val_accuracy: 0.4722\n",
            "Epoch 11/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.3844 - accuracy: 0.5694 - val_loss: 1.5227 - val_accuracy: 0.6250\n",
            "Epoch 12/85\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.3274 - accuracy: 0.6042 - val_loss: 1.6438 - val_accuracy: 0.5347\n",
            "Epoch 13/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.3256 - accuracy: 0.6215 - val_loss: 1.6758 - val_accuracy: 0.5208\n",
            "Epoch 14/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.3409 - accuracy: 0.6233 - val_loss: 1.7486 - val_accuracy: 0.4306\n",
            "Epoch 15/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.2784 - accuracy: 0.6389 - val_loss: 1.4927 - val_accuracy: 0.6111\n",
            "Epoch 16/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 1.2833 - accuracy: 0.6476 - val_loss: 1.7107 - val_accuracy: 0.5069\n",
            "Epoch 17/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.2696 - accuracy: 0.6606 - val_loss: 1.6290 - val_accuracy: 0.6042\n",
            "Epoch 18/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.2611 - accuracy: 0.6476 - val_loss: 1.4593 - val_accuracy: 0.6181\n",
            "Epoch 19/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.2462 - accuracy: 0.6398 - val_loss: 1.6364 - val_accuracy: 0.5208\n",
            "Epoch 20/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.1600 - accuracy: 0.6910 - val_loss: 1.5416 - val_accuracy: 0.5486\n",
            "Epoch 21/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 1.1007 - accuracy: 0.7179 - val_loss: 1.3956 - val_accuracy: 0.6458\n",
            "Epoch 22/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0852 - accuracy: 0.7300 - val_loss: 1.3995 - val_accuracy: 0.6319\n",
            "Epoch 23/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0337 - accuracy: 0.7465 - val_loss: 1.3972 - val_accuracy: 0.6181\n",
            "Epoch 24/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.0462 - accuracy: 0.7231 - val_loss: 1.5422 - val_accuracy: 0.6111\n",
            "Epoch 25/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 1.0769 - accuracy: 0.7231 - val_loss: 1.5040 - val_accuracy: 0.6042\n",
            "Epoch 26/85\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 1.0405 - accuracy: 0.7292 - val_loss: 1.5877 - val_accuracy: 0.5278\n",
            "Epoch 27/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0331 - accuracy: 0.7535 - val_loss: 1.3710 - val_accuracy: 0.6597\n",
            "Epoch 28/85\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 1.0360 - accuracy: 0.7483 - val_loss: 1.3670 - val_accuracy: 0.6597\n",
            "Epoch 29/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.9906 - accuracy: 0.7509 - val_loss: 1.5142 - val_accuracy: 0.6111\n",
            "Epoch 30/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.9366 - accuracy: 0.7804 - val_loss: 1.2632 - val_accuracy: 0.6667\n",
            "Epoch 31/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 1.0168 - accuracy: 0.7465 - val_loss: 1.8253 - val_accuracy: 0.5278\n",
            "Epoch 32/85\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.9765 - accuracy: 0.7769 - val_loss: 1.5730 - val_accuracy: 0.6111\n",
            "Epoch 33/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.9412 - accuracy: 0.7717 - val_loss: 1.3326 - val_accuracy: 0.6806\n",
            "Epoch 34/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.9313 - accuracy: 0.7821 - val_loss: 1.3243 - val_accuracy: 0.6458\n",
            "Epoch 35/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.9331 - accuracy: 0.7847 - val_loss: 1.3695 - val_accuracy: 0.6458\n",
            "Epoch 36/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.8666 - accuracy: 0.8125 - val_loss: 1.4578 - val_accuracy: 0.6667\n",
            "Epoch 37/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.7830 - accuracy: 0.8177 - val_loss: 1.2626 - val_accuracy: 0.7083\n",
            "Epoch 38/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.7801 - accuracy: 0.8220 - val_loss: 1.2370 - val_accuracy: 0.6806\n",
            "Epoch 39/85\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 0.7855 - accuracy: 0.8247 - val_loss: 1.5986 - val_accuracy: 0.5694\n",
            "Epoch 40/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.8321 - accuracy: 0.8056 - val_loss: 1.4311 - val_accuracy: 0.5903\n",
            "Epoch 41/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.7669 - accuracy: 0.8368 - val_loss: 1.4516 - val_accuracy: 0.6528\n",
            "Epoch 42/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.7737 - accuracy: 0.8368 - val_loss: 1.3214 - val_accuracy: 0.6667\n",
            "Epoch 43/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.7328 - accuracy: 0.8481 - val_loss: 2.0327 - val_accuracy: 0.5069\n",
            "Epoch 44/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.7319 - accuracy: 0.8516 - val_loss: 1.5147 - val_accuracy: 0.6389\n",
            "Epoch 45/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.7739 - accuracy: 0.8411 - val_loss: 1.2416 - val_accuracy: 0.7083\n",
            "Epoch 46/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.7123 - accuracy: 0.8516 - val_loss: 1.2308 - val_accuracy: 0.7014\n",
            "Epoch 47/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.7854 - accuracy: 0.8429 - val_loss: 1.4391 - val_accuracy: 0.6667\n",
            "Epoch 48/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.7545 - accuracy: 0.8559 - val_loss: 1.3102 - val_accuracy: 0.7014\n",
            "Epoch 49/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.7000 - accuracy: 0.8637 - val_loss: 1.2740 - val_accuracy: 0.6875\n",
            "Epoch 50/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.6459 - accuracy: 0.8819 - val_loss: 1.2530 - val_accuracy: 0.7014\n",
            "Epoch 51/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.6326 - accuracy: 0.8733 - val_loss: 1.3855 - val_accuracy: 0.6944\n",
            "Epoch 52/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.6414 - accuracy: 0.8698 - val_loss: 1.2581 - val_accuracy: 0.6875\n",
            "Epoch 53/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.6246 - accuracy: 0.8802 - val_loss: 1.4451 - val_accuracy: 0.6736\n",
            "Epoch 54/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.5912 - accuracy: 0.8924 - val_loss: 1.4004 - val_accuracy: 0.6944\n",
            "Epoch 55/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.6091 - accuracy: 0.8863 - val_loss: 1.2126 - val_accuracy: 0.7014\n",
            "Epoch 56/85\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.6650 - accuracy: 0.8707 - val_loss: 1.3294 - val_accuracy: 0.6597\n",
            "Epoch 57/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.6440 - accuracy: 0.8906 - val_loss: 1.4713 - val_accuracy: 0.6181\n",
            "Epoch 58/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.6166 - accuracy: 0.8932 - val_loss: 1.3075 - val_accuracy: 0.7431\n",
            "Epoch 59/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.5971 - accuracy: 0.8793 - val_loss: 1.1768 - val_accuracy: 0.7708\n",
            "Epoch 60/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.6446 - accuracy: 0.8663 - val_loss: 1.6693 - val_accuracy: 0.6250\n",
            "Epoch 61/85\n",
            "30/30 [==============================] - 15s 486ms/step - loss: 0.6902 - accuracy: 0.8585 - val_loss: 1.5356 - val_accuracy: 0.6389\n",
            "Epoch 62/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.6345 - accuracy: 0.8854 - val_loss: 1.5466 - val_accuracy: 0.6875\n",
            "Epoch 63/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5854 - accuracy: 0.9002 - val_loss: 1.5518 - val_accuracy: 0.6528\n",
            "Epoch 64/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5701 - accuracy: 0.8984 - val_loss: 1.3701 - val_accuracy: 0.6319\n",
            "Epoch 65/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.6009 - accuracy: 0.8924 - val_loss: 1.4363 - val_accuracy: 0.6319\n",
            "Epoch 66/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.5935 - accuracy: 0.8932 - val_loss: 1.2434 - val_accuracy: 0.7292\n",
            "Epoch 67/85\n",
            "30/30 [==============================] - 15s 491ms/step - loss: 0.5705 - accuracy: 0.9002 - val_loss: 1.2678 - val_accuracy: 0.7083\n",
            "Epoch 68/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.6069 - accuracy: 0.8941 - val_loss: 1.4784 - val_accuracy: 0.6806\n",
            "Epoch 69/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5975 - accuracy: 0.9010 - val_loss: 1.4361 - val_accuracy: 0.6736\n",
            "Epoch 70/85\n",
            "30/30 [==============================] - 15s 488ms/step - loss: 0.5866 - accuracy: 0.8924 - val_loss: 1.4319 - val_accuracy: 0.6944\n",
            "Epoch 71/85\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 0.5780 - accuracy: 0.8976 - val_loss: 1.5717 - val_accuracy: 0.6736\n",
            "Epoch 72/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5372 - accuracy: 0.9062 - val_loss: 1.6443 - val_accuracy: 0.6528\n",
            "Epoch 73/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5277 - accuracy: 0.9184 - val_loss: 1.1921 - val_accuracy: 0.7500\n",
            "Epoch 74/85\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.5337 - accuracy: 0.9089 - val_loss: 1.4013 - val_accuracy: 0.6875\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 1.2519 - accuracy: 0.7361\n",
            "Test loss of the model is -  1.2519431114196777\n",
            "Test accuracy of the model is -  73.61111044883728 %\n",
            "EPOCHS:  98\n",
            "BATCH_SIZE:  62\n",
            "LEARNING_RATE:  0.0032872209120587683\n",
            "Epoch 1/98\n",
            "19/19 [==============================] - 23s 837ms/step - loss: 23.5788 - accuracy: 0.1632 - val_loss: 3.6967 - val_accuracy: 0.1528\n",
            "Epoch 2/98\n",
            "19/19 [==============================] - 15s 810ms/step - loss: 2.8364 - accuracy: 0.2439 - val_loss: 2.6565 - val_accuracy: 0.2222\n",
            "Epoch 3/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 3.5497 - accuracy: 0.2622 - val_loss: 2.6279 - val_accuracy: 0.3125\n",
            "Epoch 4/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 2.1570 - accuracy: 0.3003 - val_loss: 2.1062 - val_accuracy: 0.3472\n",
            "Epoch 5/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.9234 - accuracy: 0.3628 - val_loss: 1.9113 - val_accuracy: 0.3750\n",
            "Epoch 6/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.8214 - accuracy: 0.3655 - val_loss: 1.9982 - val_accuracy: 0.2292\n",
            "Epoch 7/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.8096 - accuracy: 0.3750 - val_loss: 1.8970 - val_accuracy: 0.3681\n",
            "Epoch 8/98\n",
            "19/19 [==============================] - 15s 811ms/step - loss: 1.7574 - accuracy: 0.4115 - val_loss: 1.8356 - val_accuracy: 0.4028\n",
            "Epoch 9/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.7011 - accuracy: 0.4245 - val_loss: 1.9883 - val_accuracy: 0.3194\n",
            "Epoch 10/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.6623 - accuracy: 0.4531 - val_loss: 1.9915 - val_accuracy: 0.2986\n",
            "Epoch 11/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 1.6411 - accuracy: 0.4609 - val_loss: 1.8650 - val_accuracy: 0.3125\n",
            "Epoch 12/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 1.5891 - accuracy: 0.4766 - val_loss: 1.8290 - val_accuracy: 0.3750\n",
            "Epoch 13/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.5875 - accuracy: 0.4800 - val_loss: 1.8476 - val_accuracy: 0.3125\n",
            "Epoch 14/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.6138 - accuracy: 0.4635 - val_loss: 1.8379 - val_accuracy: 0.4375\n",
            "Epoch 15/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.5167 - accuracy: 0.5243 - val_loss: 1.8312 - val_accuracy: 0.4583\n",
            "Epoch 16/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.4629 - accuracy: 0.5469 - val_loss: 1.7474 - val_accuracy: 0.5069\n",
            "Epoch 17/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.4978 - accuracy: 0.5278 - val_loss: 1.8621 - val_accuracy: 0.3403\n",
            "Epoch 18/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.4638 - accuracy: 0.5503 - val_loss: 1.7974 - val_accuracy: 0.5208\n",
            "Epoch 19/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.4933 - accuracy: 0.5590 - val_loss: 1.8943 - val_accuracy: 0.4375\n",
            "Epoch 20/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4595 - accuracy: 0.5668 - val_loss: 1.8256 - val_accuracy: 0.4167\n",
            "Epoch 21/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.4123 - accuracy: 0.5885 - val_loss: 1.7033 - val_accuracy: 0.4514\n",
            "Epoch 22/98\n",
            "19/19 [==============================] - 15s 809ms/step - loss: 1.4244 - accuracy: 0.5530 - val_loss: 2.2143 - val_accuracy: 0.3819\n",
            "Epoch 23/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.3562 - accuracy: 0.6111 - val_loss: 1.6859 - val_accuracy: 0.5417\n",
            "Epoch 24/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.3200 - accuracy: 0.6293 - val_loss: 1.8725 - val_accuracy: 0.3819\n",
            "Epoch 25/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.3854 - accuracy: 0.6189 - val_loss: 1.7418 - val_accuracy: 0.5139\n",
            "Epoch 26/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.4088 - accuracy: 0.6189 - val_loss: 1.7945 - val_accuracy: 0.5278\n",
            "Epoch 27/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.3407 - accuracy: 0.6354 - val_loss: 1.7604 - val_accuracy: 0.4653\n",
            "Epoch 28/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2720 - accuracy: 0.6554 - val_loss: 2.0249 - val_accuracy: 0.4375\n",
            "Epoch 29/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.3060 - accuracy: 0.6458 - val_loss: 1.8296 - val_accuracy: 0.4583\n",
            "Epoch 30/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2729 - accuracy: 0.6667 - val_loss: 1.8685 - val_accuracy: 0.4375\n",
            "Epoch 31/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2642 - accuracy: 0.6823 - val_loss: 1.7943 - val_accuracy: 0.5139\n",
            "Epoch 32/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.2696 - accuracy: 0.6693 - val_loss: 1.6165 - val_accuracy: 0.5486\n",
            "Epoch 33/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.3069 - accuracy: 0.6528 - val_loss: 1.7851 - val_accuracy: 0.4792\n",
            "Epoch 34/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2239 - accuracy: 0.6823 - val_loss: 1.8812 - val_accuracy: 0.4167\n",
            "Epoch 35/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.1664 - accuracy: 0.7101 - val_loss: 1.6562 - val_accuracy: 0.5556\n",
            "Epoch 36/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.1735 - accuracy: 0.7005 - val_loss: 1.7753 - val_accuracy: 0.4792\n",
            "Epoch 37/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.1861 - accuracy: 0.7127 - val_loss: 1.5798 - val_accuracy: 0.6042\n",
            "Epoch 38/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2274 - accuracy: 0.7092 - val_loss: 1.9324 - val_accuracy: 0.4444\n",
            "Epoch 39/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.2453 - accuracy: 0.6910 - val_loss: 1.8088 - val_accuracy: 0.5694\n",
            "Epoch 40/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.1433 - accuracy: 0.7396 - val_loss: 1.6037 - val_accuracy: 0.5625\n",
            "Epoch 41/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 1.0885 - accuracy: 0.7439 - val_loss: 1.7759 - val_accuracy: 0.4514\n",
            "Epoch 42/98\n",
            "19/19 [==============================] - 15s 813ms/step - loss: 1.0816 - accuracy: 0.7526 - val_loss: 1.8890 - val_accuracy: 0.4722\n",
            "Epoch 43/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.0788 - accuracy: 0.7387 - val_loss: 1.7625 - val_accuracy: 0.5139\n",
            "Epoch 44/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.0575 - accuracy: 0.7457 - val_loss: 1.6735 - val_accuracy: 0.5486\n",
            "Epoch 45/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.0465 - accuracy: 0.7769 - val_loss: 1.7033 - val_accuracy: 0.5139\n",
            "Epoch 46/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0579 - accuracy: 0.7500 - val_loss: 1.5520 - val_accuracy: 0.5972\n",
            "Epoch 47/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.0759 - accuracy: 0.7335 - val_loss: 1.4941 - val_accuracy: 0.5764\n",
            "Epoch 48/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 0.9769 - accuracy: 0.7821 - val_loss: 1.8161 - val_accuracy: 0.5139\n",
            "Epoch 49/98\n",
            "19/19 [==============================] - 16s 845ms/step - loss: 1.0059 - accuracy: 0.7882 - val_loss: 1.5958 - val_accuracy: 0.5208\n",
            "Epoch 50/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 0.9773 - accuracy: 0.7769 - val_loss: 1.4552 - val_accuracy: 0.6181\n",
            "Epoch 51/98\n",
            "19/19 [==============================] - 15s 810ms/step - loss: 0.9785 - accuracy: 0.7691 - val_loss: 1.6423 - val_accuracy: 0.6319\n",
            "Epoch 52/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 0.9456 - accuracy: 0.7899 - val_loss: 1.6509 - val_accuracy: 0.5764\n",
            "Epoch 53/98\n",
            "19/19 [==============================] - 16s 841ms/step - loss: 1.0342 - accuracy: 0.7674 - val_loss: 1.9948 - val_accuracy: 0.5278\n",
            "Epoch 54/98\n",
            "19/19 [==============================] - 15s 807ms/step - loss: 1.0215 - accuracy: 0.7769 - val_loss: 1.5223 - val_accuracy: 0.5903\n",
            "Epoch 55/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 0.9976 - accuracy: 0.7769 - val_loss: 1.4493 - val_accuracy: 0.6250\n",
            "Epoch 56/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 0.9537 - accuracy: 0.7830 - val_loss: 1.5406 - val_accuracy: 0.6250\n",
            "Epoch 57/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 1.0126 - accuracy: 0.7561 - val_loss: 1.3955 - val_accuracy: 0.6875\n",
            "Epoch 58/98\n",
            "19/19 [==============================] - 16s 844ms/step - loss: 0.9818 - accuracy: 0.7795 - val_loss: 1.4447 - val_accuracy: 0.6319\n",
            "Epoch 59/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 0.9040 - accuracy: 0.8177 - val_loss: 1.4171 - val_accuracy: 0.6319\n",
            "Epoch 60/98\n",
            "19/19 [==============================] - 15s 809ms/step - loss: 0.9428 - accuracy: 0.7760 - val_loss: 1.5817 - val_accuracy: 0.5972\n",
            "Epoch 61/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 0.9167 - accuracy: 0.8073 - val_loss: 2.0531 - val_accuracy: 0.4861\n",
            "Epoch 62/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 0.9970 - accuracy: 0.7778 - val_loss: 2.5838 - val_accuracy: 0.4236\n",
            "Epoch 63/98\n",
            "19/19 [==============================] - 15s 808ms/step - loss: 1.1365 - accuracy: 0.7509 - val_loss: 1.9962 - val_accuracy: 0.5139\n",
            "Epoch 64/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 1.0245 - accuracy: 0.7908 - val_loss: 1.7806 - val_accuracy: 0.5208\n",
            "Epoch 65/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.9277 - accuracy: 0.8194 - val_loss: 1.5044 - val_accuracy: 0.5972\n",
            "Epoch 66/98\n",
            "19/19 [==============================] - 15s 806ms/step - loss: 0.8726 - accuracy: 0.8264 - val_loss: 1.5635 - val_accuracy: 0.5764\n",
            "Epoch 67/98\n",
            "19/19 [==============================] - 16s 843ms/step - loss: 0.9413 - accuracy: 0.7969 - val_loss: 1.6736 - val_accuracy: 0.5556\n",
            "Epoch 68/98\n",
            "19/19 [==============================] - 16s 846ms/step - loss: 0.9440 - accuracy: 0.7995 - val_loss: 1.4580 - val_accuracy: 0.6319\n",
            "Epoch 69/98\n",
            "19/19 [==============================] - 15s 809ms/step - loss: 0.9210 - accuracy: 0.8203 - val_loss: 1.7665 - val_accuracy: 0.5625\n",
            "Epoch 70/98\n",
            "19/19 [==============================] - 16s 840ms/step - loss: 0.9005 - accuracy: 0.8064 - val_loss: 1.9939 - val_accuracy: 0.5417\n",
            "Epoch 71/98\n",
            "19/19 [==============================] - 16s 842ms/step - loss: 0.9252 - accuracy: 0.8090 - val_loss: 1.7280 - val_accuracy: 0.5417\n",
            "Epoch 72/98\n",
            "19/19 [==============================] - 15s 809ms/step - loss: 0.8694 - accuracy: 0.8247 - val_loss: 1.5127 - val_accuracy: 0.6319\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 1.5379 - accuracy: 0.5972\n",
            "Test loss of the model is -  1.5378657579421997\n",
            "Test accuracy of the model is -  59.72222089767456 %\n",
            "Iteration:   1 | best local fitness (cost): 73.6111104\n",
            "EPOCHS:  97\n",
            "BATCH_SIZE:  50\n",
            "LEARNING_RATE:  0.003911635292154655\n",
            "Epoch 1/97\n",
            "24/24 [==============================] - 21s 656ms/step - loss: 39.3960 - accuracy: 0.2309 - val_loss: 2.5602 - val_accuracy: 0.2639\n",
            "Epoch 2/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 2.4783 - accuracy: 0.2986 - val_loss: 2.9450 - val_accuracy: 0.1597\n",
            "Epoch 3/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 2.2461 - accuracy: 0.3168 - val_loss: 2.6512 - val_accuracy: 0.2292\n",
            "Epoch 4/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 2.0777 - accuracy: 0.3472 - val_loss: 2.2409 - val_accuracy: 0.3333\n",
            "Epoch 5/97\n",
            "24/24 [==============================] - 15s 630ms/step - loss: 2.2481 - accuracy: 0.3507 - val_loss: 2.2142 - val_accuracy: 0.2431\n",
            "Epoch 6/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 2.0606 - accuracy: 0.3845 - val_loss: 2.3034 - val_accuracy: 0.2014\n",
            "Epoch 7/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.9457 - accuracy: 0.3976 - val_loss: 2.0662 - val_accuracy: 0.3958\n",
            "Epoch 8/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 2.0733 - accuracy: 0.3863 - val_loss: 2.1255 - val_accuracy: 0.4167\n",
            "Epoch 9/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.9161 - accuracy: 0.4167 - val_loss: 1.9107 - val_accuracy: 0.3819\n",
            "Epoch 10/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.8147 - accuracy: 0.4280 - val_loss: 1.9552 - val_accuracy: 0.3611\n",
            "Epoch 11/97\n",
            "24/24 [==============================] - 15s 637ms/step - loss: 1.7551 - accuracy: 0.4392 - val_loss: 2.1134 - val_accuracy: 0.3819\n",
            "Epoch 12/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.8654 - accuracy: 0.4054 - val_loss: 1.9856 - val_accuracy: 0.4097\n",
            "Epoch 13/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.8254 - accuracy: 0.4470 - val_loss: 2.0111 - val_accuracy: 0.3056\n",
            "Epoch 14/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.8544 - accuracy: 0.4540 - val_loss: 1.9308 - val_accuracy: 0.3681\n",
            "Epoch 15/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.8460 - accuracy: 0.4418 - val_loss: 1.9959 - val_accuracy: 0.3958\n",
            "Epoch 16/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7964 - accuracy: 0.4583 - val_loss: 1.8352 - val_accuracy: 0.4583\n",
            "Epoch 17/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.7670 - accuracy: 0.4592 - val_loss: 1.8854 - val_accuracy: 0.4028\n",
            "Epoch 18/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.6802 - accuracy: 0.4974 - val_loss: 1.8937 - val_accuracy: 0.3889\n",
            "Epoch 19/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.6832 - accuracy: 0.4948 - val_loss: 1.9141 - val_accuracy: 0.3681\n",
            "Epoch 20/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.8560 - accuracy: 0.4670 - val_loss: 1.9431 - val_accuracy: 0.4236\n",
            "Epoch 21/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.8218 - accuracy: 0.4818 - val_loss: 2.0375 - val_accuracy: 0.3958\n",
            "Epoch 22/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.7330 - accuracy: 0.4766 - val_loss: 1.8062 - val_accuracy: 0.4861\n",
            "Epoch 23/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.6136 - accuracy: 0.5208 - val_loss: 1.7524 - val_accuracy: 0.4444\n",
            "Epoch 24/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.5810 - accuracy: 0.5113 - val_loss: 1.6742 - val_accuracy: 0.5208\n",
            "Epoch 25/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.5093 - accuracy: 0.5443 - val_loss: 1.8832 - val_accuracy: 0.3681\n",
            "Epoch 26/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.7681 - accuracy: 0.4818 - val_loss: 2.0367 - val_accuracy: 0.4097\n",
            "Epoch 27/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.7760 - accuracy: 0.4922 - val_loss: 1.9000 - val_accuracy: 0.4722\n",
            "Epoch 28/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.5251 - accuracy: 0.5608 - val_loss: 1.7744 - val_accuracy: 0.4722\n",
            "Epoch 29/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.5088 - accuracy: 0.5538 - val_loss: 1.8588 - val_accuracy: 0.4167\n",
            "Epoch 30/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7395 - accuracy: 0.4913 - val_loss: 1.9488 - val_accuracy: 0.4792\n",
            "Epoch 31/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.7784 - accuracy: 0.5035 - val_loss: 1.9061 - val_accuracy: 0.4792\n",
            "Epoch 32/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.5781 - accuracy: 0.5668 - val_loss: 1.8219 - val_accuracy: 0.4375\n",
            "Epoch 33/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.6700 - accuracy: 0.5234 - val_loss: 1.8808 - val_accuracy: 0.4931\n",
            "Epoch 34/97\n",
            "24/24 [==============================] - 15s 634ms/step - loss: 1.5612 - accuracy: 0.5616 - val_loss: 1.7414 - val_accuracy: 0.5347\n",
            "Epoch 35/97\n",
            "24/24 [==============================] - 15s 635ms/step - loss: 1.4845 - accuracy: 0.5825 - val_loss: 1.8627 - val_accuracy: 0.4583\n",
            "Epoch 36/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.5586 - accuracy: 0.5599 - val_loss: 1.9255 - val_accuracy: 0.3333\n",
            "Epoch 37/97\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 1.6146 - accuracy: 0.5391 - val_loss: 1.9322 - val_accuracy: 0.4097\n",
            "Epoch 38/97\n",
            "24/24 [==============================] - 15s 632ms/step - loss: 1.5934 - accuracy: 0.5616 - val_loss: 1.9359 - val_accuracy: 0.4583\n",
            "Epoch 39/97\n",
            "24/24 [==============================] - 15s 633ms/step - loss: 1.7093 - accuracy: 0.5373 - val_loss: 1.8911 - val_accuracy: 0.4861\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.8417 - accuracy: 0.4306\n",
            "Test loss of the model is -  1.841666340827942\n",
            "Test accuracy of the model is -  43.05555522441864 %\n",
            "EPOCHS:  87\n",
            "BATCH_SIZE:  36\n",
            "LEARNING_RATE:  0.0028560139650024214\n",
            "Epoch 1/87\n",
            "32/32 [==============================] - 22s 485ms/step - loss: 18.2167 - accuracy: 0.2153 - val_loss: 2.8641 - val_accuracy: 0.1806\n",
            "Epoch 2/87\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 2.2735 - accuracy: 0.3255 - val_loss: 2.3329 - val_accuracy: 0.2153\n",
            "Epoch 3/87\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 1.9238 - accuracy: 0.3759 - val_loss: 2.0154 - val_accuracy: 0.3056\n",
            "Epoch 4/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.8532 - accuracy: 0.3993 - val_loss: 2.0612 - val_accuracy: 0.3403\n",
            "Epoch 5/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.7879 - accuracy: 0.4236 - val_loss: 1.9164 - val_accuracy: 0.4306\n",
            "Epoch 6/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7381 - accuracy: 0.4366 - val_loss: 1.8842 - val_accuracy: 0.3750\n",
            "Epoch 7/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7113 - accuracy: 0.4323 - val_loss: 1.9860 - val_accuracy: 0.2639\n",
            "Epoch 8/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.7054 - accuracy: 0.4497 - val_loss: 1.7816 - val_accuracy: 0.4167\n",
            "Epoch 9/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.6605 - accuracy: 0.4757 - val_loss: 1.7842 - val_accuracy: 0.4167\n",
            "Epoch 10/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.6354 - accuracy: 0.4818 - val_loss: 1.9761 - val_accuracy: 0.2708\n",
            "Epoch 11/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.6027 - accuracy: 0.5078 - val_loss: 1.8504 - val_accuracy: 0.3889\n",
            "Epoch 12/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.5763 - accuracy: 0.5043 - val_loss: 1.8022 - val_accuracy: 0.4167\n",
            "Epoch 13/87\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.5265 - accuracy: 0.5104 - val_loss: 1.8858 - val_accuracy: 0.3819\n",
            "Epoch 14/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.4315 - accuracy: 0.5564 - val_loss: 1.6742 - val_accuracy: 0.4375\n",
            "Epoch 15/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.4823 - accuracy: 0.5356 - val_loss: 1.8808 - val_accuracy: 0.3681\n",
            "Epoch 16/87\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 1.4329 - accuracy: 0.5564 - val_loss: 1.9908 - val_accuracy: 0.3194\n",
            "Epoch 17/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.4314 - accuracy: 0.5556 - val_loss: 1.6317 - val_accuracy: 0.5208\n",
            "Epoch 18/87\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.4481 - accuracy: 0.5547 - val_loss: 1.5393 - val_accuracy: 0.5764\n",
            "Epoch 19/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.3171 - accuracy: 0.6111 - val_loss: 1.5176 - val_accuracy: 0.5625\n",
            "Epoch 20/87\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.3635 - accuracy: 0.5903 - val_loss: 1.7218 - val_accuracy: 0.4653\n",
            "Epoch 21/87\n",
            "28/32 [=========================>....] - ETA: 1s - loss: 1.5807 - accuracy: 0.5437"
          ]
        }
      ],
      "source": [
        "import random\n",
        "acc = -1\n",
        "\n",
        "random.seed(0)\n",
        "def fitness(X):\n",
        "    global acc\n",
        "    EPOCHS = int(X[0])\n",
        "    BATCH_SIZE = int(X[1])\n",
        "    LEARNING_RATE = X[2]\n",
        "\n",
        "    print(\"EPOCHS: \", EPOCHS)\n",
        "    print(\"BATCH_SIZE: \", BATCH_SIZE)\n",
        "    print(\"LEARNING_RATE: \", LEARNING_RATE)\n",
        "\n",
        "    model = None\n",
        "    model = layer_structure()\n",
        "    model, early_stopping = optimize(model, LEARNING_RATE)\n",
        "\n",
        "    #training\n",
        "    start = time.time()\n",
        "    history = model.fit([video_features_train, audio_features_train], labels_train,\n",
        "                        epochs=EPOCHS,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        validation_data=([video_features_val, audio_features_val], labels_val),\n",
        "                        callbacks=[early_stopping])\n",
        "    end = time.time()\n",
        "    train_time_avg = (end - start) / 50\n",
        "\n",
        "    start=time.time()\n",
        "    score=model.evaluate([video_features_test,audio_features_test],labels_test)\n",
        "    end=time.time()\n",
        "    test_time=end-start\n",
        "    print(\"Test loss of the model is - \" , score[0])\n",
        "    print(\"Test accuracy of the model is - \" , score[1]*100 , \"%\")\n",
        "\n",
        "    if score[1]*100 > acc:\n",
        "        acc = score[1]*100\n",
        "        model.save(\"fusion_batch_normalisation_with_CSO.h5\")\n",
        "\n",
        "    return score[1]*100\n",
        "\n",
        "CSO(fitness=fitness, bound=[(80,100), (32,64), (0.001, 0.005)], n = 3, verbose = True, min = False).execute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1080518d",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "1080518d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3920731,
          "sourceId": 6816423,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 20.855104,
      "end_time": "2023-11-21T04:46:01.013419",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-21T04:45:40.158315",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}